---
title: Leave-one-out cross-validation in R
date: 2023-08-08
categories:
  - R
---

## Strategy
* Fit "straight" models
  * linear model - `fm_lm`
  * neural net with 2 layers with 3 perceptrons each - `fm_nn`
* Fit models with "Leave-one-out-cross-validation"
  * linear model - `lm_looc`
  * neural net - `nn_looc`
  * Calculate mean absolute prediction error for both model types (predict each data point based on a model that is based on all but the current data point)

## Implementation
### Init
```{r}
#| label: init
#| message: false
set.seed(123)
library('tidyverse')
library('knitr')
library('neuralnet')
library('plotly')
```

### Define function for performing leave-one-out-crossvalidation
```{r}
# A function that removes one data point from the cars data set, 
# fits either a linear model or a neural net to the remaining data 
# and returns the model prediction for the data point 
# that had been removed in the first place
# 
# Parameters:
#   * i: which data points to remove - the function is vectorized for this parameter
#   * model_type: which type of model is to be fit - either "lm" or if not "lm", a neural 
leave_one_out <- Vectorize(
  function(i, model_type) {
    training <- cars[-i, ]
    test <- cars[i, ]
    if(model_type == 'lm') {
      fm <- lm(speed ~ dist, data = training)
      pp <- predict(fm, newdata = test)
    } else if(model_type == 'nn'){
      fm <- neuralnet(speed ~ dist, 
                      linear.output = TRUE, data = training, 
                      hidden = c(3, 3), 
                      stepmax = 1e+7, threshold = .5)
      pp <- predict(fm, newdata = test)[, 1]
    } else {
      stop('Invalid model type')
    }
    return(pp)
  }, vectorize.args = 'i')
```

### Fit models
```{r}
#| cache: true
fm_lm <- lm(speed ~ dist, data = cars)
fm_nn <- neuralnet(speed ~ dist, 
                   linear.output = TRUE, data = cars, 
                   hidden = c(3, 3), 
                   stepmax = 1e+7, threshold = .5)

data <- tibble(
  cars,
  prediction_lm_straight = predict(fm_lm),
  prediction_nn_straight = predict(fm_nn, newdata = cars)[, 1],
  prediction_lm_looc = leave_one_out(1:nrow(cars), model_type = 'lm'),
  prediction_nn_looc = leave_one_out(1:nrow(cars), model_type = 'nn')) |> 
  rename(measured_speed = 'speed')
```

### Show and analyze results
```{r}
data |> 
  pivot_longer(cols = -dist, names_to = 'Method', values_to = 'speed') |> 
  ggplot(aes(dist, speed, colour = Method)) +
  geom_point() +
  labs(y = 'speed')

# the previous plot with plotly library so it can be appreciated interactively:
ggplot2::last_plot() |> ggplotly()

data_long <- data |> 
  pivot_longer(cols = -c(dist, measured_speed), names_to = 'Method',
               values_to = 'prediction') |>
  mutate(error = prediction - measured_speed,
         squarred_error = error^2)

data_long |> 
  ggplot(aes(dist, error)) + geom_point() + 
  facet_wrap(vars(Method), labeller = label_both) +
  labs(y = 'Prediction error')

data_long |> 
  group_by(Method) |> 
  summarize('Mean absolute error' = mean(abs(error)),
            'Mean squarred error' = mean(squarred_error)) |> 
  kable(align = 'c')
```

## Conclusion
* The neural net seems to overfit!