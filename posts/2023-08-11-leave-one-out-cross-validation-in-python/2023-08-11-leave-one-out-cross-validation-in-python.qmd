---
title: Leave-one-out cross-validation in Python
date: 2023-08-11
categories:
  - Python
  - 'Linear model vs neural nets'
---

## Strategy
* Look at the `cars` dataset that is shipped in `base` R
* Fit models
  * for each model, leave out one data point
  * predict the response value for that data point based on the model that is not based on that data point
  * calculate mean absolute error and mean squared error

## Implementation

### Init
#### Chunk in R to setup my Python environment (can be omitted for users with Python ready to use)
```{r}
#| label: init
library('reticulate')
use_condaenv('sbloggel', required = TRUE)
```

#### Chunk to load Python libraries and set up the data
```{python}
import pandas as pd
import statsmodels.formula.api as smf
import numpy as np
cars = pd.DataFrame(r['cars'])
```

### Show that fitting in R and Python yields identical results
```{python}
fm = smf.ols(formula = 'speed ~ dist', data = cars).fit()
fm.summary()
```

```{r}
fm <- lm(speed ~ dist, data = cars)
summary(fm)
```

### Show that prediction in R and Python yields identical results
```{python}
fm.predict(cars.iloc[0])
```

```{r}
predict(fm, cars[1, ])
```


### Perform leave-one-out-cross-validation in Python
```{python}
# prepare column for predictions:
cars['prediction'] = np.nan

# fit models:
for i in range(50):
  train = cars.drop(index = i)
  test = cars.iloc[i]
  fm = smf.ols(formula='speed ~ dist', data=train).fit()
  cars['prediction'].iloc[i] = fm.predict(test)

# calculate prediction error:
cars['error'] = cars['speed'] - cars['prediction']

# mean absolute error:
np.mean(np.abs(cars['error']))

# root mean squared error:
np.sqrt(np.mean(np.square(cars['error'])))
```

## Conclusion
* Results are identical to those produced in R: [Link](https://sbloggel.netlify.app/posts/2023-08-08-leave-one-out-cross-validation-in-r/2023-08-08-leave-one-out-cross-validation-in-r)
* Also, the discrepancy with Friedemann's results is now resolved