[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Sebastian Gerdes (email: first name dot last name at posteo dot de) and this is my personal blog. I intend to publish some posts about statistics and maybe other topics as well on this site.\nHere is the link to the blog posts!\nHere is the link to the github repository, where the source code of this blog can be found!"
  },
  {
    "objectID": "posts/2022-09-08-humidity/2022-09-08-humidity.html",
    "href": "posts/2022-09-08-humidity/2022-09-08-humidity.html",
    "title": "Humidity",
    "section": "",
    "text": "# devtools::install_github('sebastian-gerdes/smisc')\nlibrary('smisc')\nlibrary('knitr')\nlibrary('tibble') \nlibrary('lattice')\nplot(absolute_humidity, -20, 20, log = 'y')\nvolume_of_flat &lt;- 120 * 3\nrelative_humidity_inside &lt;- 50\nrelative_humidity_outside &lt;- 70\ntemperature_inside &lt;- 20\ntemperature_outside &lt;- 0\n(water_in_air_inside &lt;- absolute_humidity(relative_humidity = relative_humidity_inside,\n                                  temperature = temperature_inside) * volume_of_flat)\n\n[1] 3.110073\n\n(water_in_air_outside &lt;- absolute_humidity(relative_humidity = relative_humidity_outside,\n                                  temperature = temperature_outside) * volume_of_flat)\n\n[1] 1.222142\n\nwater_out &lt;- water_in_air_inside - water_in_air_outside\nConclusion: Airing once with an indoor temperature of 20 degress Celsius with a relative humidity of 50% and an outdoor temperature of 0 degrees Celsius with a relative outdoor humidity of 70% transports approx. 1.9 liters of water out of the flat, assuming a volume of 360 \\(m^3\\) of the flat.\ntemperatures &lt;- seq(from = -10, to = 35)\nrelative_humidities &lt;- seq(from = 0, to = 100, by = 5)\nresult &lt;- matrix(nrow = length(temperatures), \n                 ncol = length(relative_humidities), \n                 dimnames = list(temperatures, relative_humidities))\nfor (i in 1:length(temperatures)) {\n  for (j in 1:length(relative_humidities)){\n    result[i, j] &lt;- absolute_humidity(temperature = temperatures[i], \n                                      relative_humidity = relative_humidities[j])\n  }\n}\nmy_breaks &lt;- c(0.5, 0.7, 1, 1.5, 2, 3, 4, 6, 8, 10, 12, 16, 20, 30) / 1000\ncontour(result, levels = c(0.5, 1, 2, 3, 4, 10, 20) / 1000)\n\n\n\ncontourplot(result, at = my_breaks,\n            scales=list(x=list(rot=90)), \n            xlab = 'Temperature (degrees Celsius)',\n            ylab = 'Relative humidity (%)')"
  },
  {
    "objectID": "posts/2022-09-08-humidity/2022-09-08-humidity.html#absolute-humidity-in-1-m3-at-a-relative-humiditiy-of-100",
    "href": "posts/2022-09-08-humidity/2022-09-08-humidity.html#absolute-humidity-in-1-m3-at-a-relative-humiditiy-of-100",
    "title": "Humidity",
    "section": "Absolute humidity in 1 \\(m^3\\) at a relative humiditiy of 100%",
    "text": "Absolute humidity in 1 \\(m^3\\) at a relative humiditiy of 100%\n\n# scenario 1:\ntemperatures &lt;- seq(from = -10, to = 35, by = 5)\nrelative_humidities &lt;- seq(from = 0, to = 100, by = 10)\nresult &lt;- matrix(nrow = length(temperatures), \n                 ncol = length(relative_humidities), \n                 dimnames = list(temperatures, relative_humidities))\nfor (i in 1:length(temperatures)) {\n  for (j in 1:length(relative_humidities)){\n    result[i, j] &lt;- absolute_humidity(temperature = temperatures[i], \n                                      relative_humidity = relative_humidities[j])\n  }\n}\n\nkable(round(result, digits = 2)) \n\n\n\n\n\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n\n\n\n\n-10\n0\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n-5\n0\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n0\n0\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n5\n0\n0\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.01\n0.01\n0.01\n\n\n10\n0\n0\n0.00\n0.00\n0.00\n0.00\n0.01\n0.01\n0.01\n0.01\n0.01\n\n\n15\n0\n0\n0.00\n0.00\n0.01\n0.01\n0.01\n0.01\n0.01\n0.01\n0.01\n\n\n20\n0\n0\n0.00\n0.01\n0.01\n0.01\n0.01\n0.01\n0.01\n0.02\n0.02\n\n\n25\n0\n0\n0.00\n0.01\n0.01\n0.01\n0.01\n0.02\n0.02\n0.02\n0.02\n\n\n30\n0\n0\n0.01\n0.01\n0.01\n0.02\n0.02\n0.02\n0.02\n0.03\n0.03\n\n\n35\n0\n0\n0.01\n0.01\n0.02\n0.02\n0.02\n0.03\n0.03\n0.04\n0.04\n\n\n\n\n# scenario 2:\ntemperatures &lt;- -10:30\nabs_humidity &lt;- round(absolute_humidity(temperature = temperatures), digits = 3)\nkable(tibble(temperatures = temperatures, abs_humidity = abs_humidity))\n\n\n\n\ntemperatures\nabs_humidity\n\n\n\n\n-10\n0.002\n\n\n-9\n0.003\n\n\n-8\n0.003\n\n\n-7\n0.003\n\n\n-6\n0.003\n\n\n-5\n0.003\n\n\n-4\n0.004\n\n\n-3\n0.004\n\n\n-2\n0.004\n\n\n-1\n0.005\n\n\n0\n0.005\n\n\n1\n0.005\n\n\n2\n0.006\n\n\n3\n0.006\n\n\n4\n0.006\n\n\n5\n0.007\n\n\n6\n0.007\n\n\n7\n0.008\n\n\n8\n0.008\n\n\n9\n0.009\n\n\n10\n0.009\n\n\n11\n0.010\n\n\n12\n0.011\n\n\n13\n0.011\n\n\n14\n0.012\n\n\n15\n0.013\n\n\n16\n0.014\n\n\n17\n0.014\n\n\n18\n0.015\n\n\n19\n0.016\n\n\n20\n0.017\n\n\n21\n0.018\n\n\n22\n0.019\n\n\n23\n0.021\n\n\n24\n0.022\n\n\n25\n0.023\n\n\n26\n0.024\n\n\n27\n0.026\n\n\n28\n0.027\n\n\n29\n0.029\n\n\n30\n0.030"
  },
  {
    "objectID": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#generalized-linear-model",
    "href": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#generalized-linear-model",
    "title": "Model meadow",
    "section": "Generalized linear model",
    "text": "Generalized linear model\n\nBinary data\n\n\nCount data"
  },
  {
    "objectID": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#mixed-effect-models",
    "href": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#mixed-effect-models",
    "title": "Model meadow",
    "section": "Mixed effect models",
    "text": "Mixed effect models"
  },
  {
    "objectID": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#models-for-survival-data",
    "href": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#models-for-survival-data",
    "title": "Model meadow",
    "section": "Models for survival data",
    "text": "Models for survival data\n\nKaplan-Meier\n\n\nCox-PH\n\n\nCompeting risks\n\n\nMultistate models\n\nlibrary(survival)\nlibrary(mstate)\ntmat &lt;- transMat(list(c(2,3,4), c(3,4), c(4), c()), c('tox', 'twist', 'rel', 'death'))\n\ndata &lt;- data.frame(id = c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5),\n                   from = c(1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1), \n                   to = c(2, 3, 4, 3, 4, 2, 3, 4, 3, 4, 4, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4),\n                   start_time = c(0, 0, 0, 5, 5, 0, 0, 0, 4, 4, 8, 9, 0, 0, 0, 0 , 0 , 0, 0, 0, 0),\n                   stop_time = c(5, 5, 5, 8, 8, 4, 4, 4, 9, 9, 12, 13, 2, 2, 2, 3, 3, 3, 7, 7, 7),\n                   status = c(1, 0, 0, 0, 1, 1, 0 , 0 , 0, 1, 0, 0, 0 , 0, 1, 0 , 1, 0, 0 , 0 , 0), \n                   group = c('a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'a', 'b', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b'))\ndata$trans &lt;- data$to - 1\n\nfm &lt;- coxph(Surv(time = start_time, time2 = stop_time, event = status) ~ strata(trans), data = data)\n\nfm_msfit &lt;- msfit(object = fm, trans = tmat)\nplot(fm_msfit)\n\n\n\np_model &lt;- probtrans(fm_msfit, predt = 0)\np_model\n\n[[1]]\n  time pstate1 pstate2 pstate3 pstate4        se1       se2       se3       se4\n1    0    1.00     0.0     0.0    0.00 0.00000000 0.0000000 0.0000000 0.0000000\n2    2    0.80     0.0     0.0    0.20 0.16000000 0.0000000 0.0000000 0.1600000\n3    3    0.60     0.0     0.2    0.20 0.19209373 0.0000000 0.1552417 0.1600000\n4    4    0.40     0.2     0.2    0.20 0.18487233 0.1479114 0.1552417 0.1600000\n5    5    0.20     0.4     0.2    0.20 0.13617799 0.1756259 0.1552417 0.1600000\n6    8    0.10     0.4     0.2    0.30 0.08447551 0.1756259 0.1552417 0.1622840\n7    9    0.05     0.4     0.2    0.35 0.04908185 0.1756259 0.1552417 0.1663768\n8   13    0.05     0.4     0.2    0.35 0.04908185 0.1756259 0.1552417 0.1663768\n\n[[2]]\n  time pstate1 pstate2 pstate3 pstate4 se1 se2 se3 se4\n1    0       0       1       0       0   0   0   0   0\n2    2       0       1       0       0   0   0   0   0\n3    3       0       1       0       0   0   0   0   0\n4    4       0       1       0       0   0   0   0   0\n5    5       0       1       0       0   0   0   0   0\n6    8       0       1       0       0   0   0   0   0\n7    9       0       1       0       0   0   0   0   0\n8   13       0       1       0       0   0   0   0   0\n\n[[3]]\n  time pstate1 pstate2 pstate3 pstate4 se1 se2 se3 se4\n1    0       0       0       1       0   0   0   0   0\n2    2       0       0       1       0   0   0   0   0\n3    3       0       0       1       0   0   0   0   0\n4    4       0       0       1       0   0   0   0   0\n5    5       0       0       1       0   0   0   0   0\n6    8       0       0       1       0   0   0   0   0\n7    9       0       0       1       0   0   0   0   0\n8   13       0       0       1       0   0   0   0   0\n\n[[4]]\n  time pstate1 pstate2 pstate3 pstate4 se1 se2 se3 se4\n1    0       0       0       0       1   0   0   0   0\n2    2       0       0       0       1   0   0   0   0\n3    3       0       0       0       1   0   0   0   0\n4    4       0       0       0       1   0   0   0   0\n5    5       0       0       0       1   0   0   0   0\n6    8       0       0       0       1   0   0   0   0\n7    9       0       0       0       1   0   0   0   0\n8   13       0       0       0       1   0   0   0   0\n\n$trans\n       to\nfrom    tox twist rel death\n  tox    NA     1   2     3\n  twist  NA    NA   4     5\n  rel    NA    NA  NA     6\n  death  NA    NA  NA    NA\n\n$method\n[1] \"aalen\"\n\n$predt\n[1] 0\n\n$direction\n[1] \"forward\"\n\nattr(,\"class\")\n[1] \"probtrans\"\n\nplot(p_model, use.ggplot = TRUE)\n\n\n\nplot(p_model, use.ggplot = TRUE, type = 'separate', conf.int = 0.95,conf.type = 'log')"
  },
  {
    "objectID": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#machine-learning-models",
    "href": "posts/2022-10-19-model-meadow/2022-10-19-model-meadow.html#machine-learning-models",
    "title": "Model meadow",
    "section": "Machine learning models",
    "text": "Machine learning models\n\nNeural nets"
  },
  {
    "objectID": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html",
    "href": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html",
    "title": "Kids per person and carbon footprint",
    "section": "",
    "text": "Here I want collect a few resources on how much the number of kids you get affects your carbone footprint."
  },
  {
    "objectID": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html#background",
    "href": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html#background",
    "title": "Kids per person and carbon footprint",
    "section": "",
    "text": "Here I want collect a few resources on how much the number of kids you get affects your carbone footprint."
  },
  {
    "objectID": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html#interesting-links",
    "href": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html#interesting-links",
    "title": "Kids per person and carbon footprint",
    "section": "Interesting links",
    "text": "Interesting links\n\nhttps://iopscience.iop.org/article/10.1088/1748-9326/aa7541/meta\nhttps://www.lunduniversity.lu.se/article/four-lifestyle-choices-most-reduce-your-carbon-footprint\nhttps://www.arte.tv/de/videos/086893-003-A/re-kinderlos-dem-klima-zuliebe/"
  },
  {
    "objectID": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html#calculations",
    "href": "posts/2022-10-19-kids-per-person-and-carbon-footprint/2022-10-19-kids-per-person-and-carbon-footprint.html#calculations",
    "title": "Kids per person and carbon footprint",
    "section": "Calculations",
    "text": "Calculations\n\nnr_of_generations_considered &lt;-10\nnr_of_kids_per_person &lt;- 1.7\n\nnr_of_persons &lt;- function(nr_of_generations_considered, nr_of_kids_per_person = 1.7) {\n  responsibility_per_kid &lt;-(1/2)^(1:nr_of_generations_considered)\n  kids_per_generations &lt;- nr_of_kids_per_person^(1:nr_of_generations_considered)\n  total &lt;- sum(responsibility_per_kid * kids_per_generations)\n  return(total)\n}\n\nnr_of_persons_v &lt;- Vectorize(nr_of_persons)\n\nplot(nr_of_persons_v, 1, 100, log = 'x', xlab = 'Number of generations considered on log scale',\n     ylab = 'For how many descendents a person is responsible')\n\n\n\n\nDo calcuation with geometric series:\n\nfoo &lt;- function(nr_of_kids_per_person) {\n  1 / (1 - (nr_of_kids_per_person / 2))\n}  \nplot(foo, 0, 1.9)"
  },
  {
    "objectID": "posts/2023-03-17-goodfellow-deep-learning/2023-03-17-goodfellow-deep-learning.html#probability-and-information-theory",
    "href": "posts/2023-03-17-goodfellow-deep-learning/2023-03-17-goodfellow-deep-learning.html#probability-and-information-theory",
    "title": "Self-study: Deep Learning by Goodfellow et al.",
    "section": "Probability and Information Theory",
    "text": "Probability and Information Theory\n\n“Researchers have made compelling arguments for quantifying uncertainty using probability since at least the 1980s.”\nThree sources of uncertainty:\n\nInherent stochasticity (e. g. quantum mechanics, card shuffling)\nIncomplete observability (e. g. Monty hall problem)\nIncomplete modeling\n\nProbability of used as degree of belief\n\n\nRandom variables (3.2)\n\nnotation:\n\nrandom variable: plain typeface\nvalues it can take with lowerscript letters\nvector-valued: bold\n\n\n\n\nProbability distribution (3.3)\n\ndiscrete variables: probability mass function (notation: usually \\(P\\))\nnotation: \\(x \\sim P(x)\\)"
  },
  {
    "objectID": "posts/2023-03-17-goodfellow-deep-learning/2023-03-17-goodfellow-deep-learning.html#general-statistics",
    "href": "posts/2023-03-17-goodfellow-deep-learning/2023-03-17-goodfellow-deep-learning.html#general-statistics",
    "title": "Self-study: Deep Learning by Goodfellow et al.",
    "section": "General statistics",
    "text": "General statistics\n\nLaw of total probability\n\\(B_n\\): partition of entire sample space \\(\\rightarrow \\sum p(B_n) = 1\\) \\[\nP(A) = \\sum_n P(A \\cap B_n)\n\\]\n\n\nStatistical independence\n\\[\np(A|B) = p(A)\n\\]\n\n\nConditional probability\n\\[\nP(A | B) = \\frac{A \\cap B}{P(B)}\n\\]\n\n\nBayes` theorem\n\\[\n\\begin{align}\n\\frac{P(A|B)}{P(B|A)} &= \\frac{P(A)}{P(B)} \\\\\nP(A|B) \\cdot P(B) &= P(B|A) \\cdot P(A)\n\\end{align}\n\\]"
  },
  {
    "objectID": "posts/2023-03-17-goodfellow-deep-learning/2023-03-17-goodfellow-deep-learning.html#look-at-file-_notation.tex-in-the-corresponding-folder",
    "href": "posts/2023-03-17-goodfellow-deep-learning/2023-03-17-goodfellow-deep-learning.html#look-at-file-_notation.tex-in-the-corresponding-folder",
    "title": "Self-study: Deep Learning by Goodfellow et al.",
    "section": "Look at file “_notation.tex” in the corresponding folder!",
    "text": "Look at file “_notation.tex” in the corresponding folder!"
  },
  {
    "objectID": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html",
    "href": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html",
    "title": "Simulate time to-event-data",
    "section": "",
    "text": "In this post, two methods to draw from a survival time distribution defined by an arbitrary hazard function are demonstrated. First, some central equations of survival analysis are given in order to refresh the background and establish a consistent notation. Then, the two different approaches are demonstrated."
  },
  {
    "objectID": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#intro",
    "href": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#intro",
    "title": "Simulate time to-event-data",
    "section": "",
    "text": "In this post, two methods to draw from a survival time distribution defined by an arbitrary hazard function are demonstrated. First, some central equations of survival analysis are given in order to refresh the background and establish a consistent notation. Then, the two different approaches are demonstrated."
  },
  {
    "objectID": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#mathematical-aspects",
    "href": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#mathematical-aspects",
    "title": "Simulate time to-event-data",
    "section": "Mathematical aspects",
    "text": "Mathematical aspects\n\nTaken from wikipedia - at this wikipedia page also further explanation can be found\nSurvival function \\(S\\) \\[ S(t) = Pr(T &gt; t) \\]\nHazard function \\(\\lambda\\) \\[ \\lambda(t) = - S'(t) / S(t) \\]\nCumulative hazard function \\(\\Lambda\\) \\[ \\Lambda(t)  = \\int_0^t{\\lambda(u) du} \\]\nRelation between \\(\\Lambda\\) and \\(S\\) \\[ S(t) = exp(-\\Lambda(t)) \\]"
  },
  {
    "objectID": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#ad-hoc-code-to-draw-from-survival-time-distribution",
    "href": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#ad-hoc-code-to-draw-from-survival-time-distribution",
    "title": "Simulate time to-event-data",
    "section": "Ad hoc code to draw from survival time distribution",
    "text": "Ad hoc code to draw from survival time distribution\n\nset.seed(1)\nlibrary('survival')\n\n# define hazard function:\nlambda &lt;- function(t) {\n  abs(sin(t))\n}\n\n\n# hazard for t = 7 and t = 12:\nlambda(c(7, 12)) \n\n[1] 0.6569866 0.5365729\n\n# plot hazard function:\nplot(lambda, from = 0, to = 10, xlab = 't', ylab = expression(lambda))\n\n\n\n# define function that computes cumulative hazard function:\nLambda &lt;- Vectorize(\n  function(t) {\n    integrate(lambda,\n              subdivisions = 1e3L,\n              lower = 0, \n              upper = t)$value\n  })\n\n# cumulative hazard for t = 3\nLambda(3) \n\n[1] 1.989992\n\n# plot cumulative hazard function:\nplot(Lambda, from = 0, to = 10, xlab = 't', ylab = expression(Lambda))\n\n\n\n# define function that computes survival function \n# from cumulative hazard function:\nS &lt;- Vectorize(\n  function(t) {\n    exp(-Lambda(t))\n  })\n\n# plot survival function:\nplot(S, from = 0, to = 10, xlab = 't')\n\n\n\n# determine at which time cumulative hazard\n# reaches 2e1 (i. e. S(t) &lt; 1e-8)\n# the value is used as upper bound for\n# optimization to find the quantile\nupper_bound &lt;- optimize(\n  function(x) {\n    abs(Lambda(x) - 2e1)\n  }, \n  interval = c(0, 1e2))$minimum\n\n# define function to compute quantile of survival function\nquantile_function &lt;- Vectorize(\n  function(t) {\n    optimize(function(x) {\n      abs(S(x) - t)}, \n      interval = c(0, upper_bound))$min\n  })\n\n# compute some quantiles for hazard function\n# that has been specified above:\nquantile_function(c(0.25, 0.5, 0.75))\n\n[1] 1.9674130 1.2589101 0.7779829\n\n# evaluate how long it takes to determine 10 quantiles:\nmicrobenchmark::microbenchmark(quantile_function(1:10))\n\nWarning in microbenchmark::microbenchmark(quantile_function(1:10)): less\naccurate nanosecond times to avoid potential integer overflows\n\n\nUnit: milliseconds\n                    expr     min      lq     mean   median       uq      max\n quantile_function(1:10) 9.98391 10.4377 11.33159 10.77966 12.46623 15.01235\n neval\n   100\n\n# draw n random numbers from survival distribution \n# defined by hazard function above\n(times &lt;- quantile_function(runif(n = 20)))\n\n [1] 0.9040743 1.0566904 2.0173300 1.9328205 0.8170795 1.3620799 2.4072092\n [8] 0.7842570 3.8702329 0.5462974 1.0317729 1.1427625 1.6834271 1.3608340\n[15] 1.2579906 2.3602768 1.1977742 4.2861974 1.8556640 2.1505993\n\nplot(survfit(Surv(times) ~ 1), xlab = 't', ylab = 'S')"
  },
  {
    "objectID": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#more-sophisticated-solution-using-the-coxed-package",
    "href": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#more-sophisticated-solution-using-the-coxed-package",
    "title": "Simulate time to-event-data",
    "section": "More sophisticated solution using the coxed package",
    "text": "More sophisticated solution using the coxed package\n\nSolution found here:\n\n\nlibrary('coxed')\n\nmy.hazard &lt;- function(t){ \n  abs(sin(t)) * 0.01\n}\n\nsimdata &lt;- sim.survdata(N = 100, \n                        T = 1000, \n                        hazard.fun = my.hazard)\n\nWarning in FUN(X[[i]], ...): 0 additional observations right-censored because the user-supplied hazard function\n                                  is nonzero at the latest timepoint. To avoid these extra censored observations, increase T\n\nplot(survfit(Surv(simdata$data$y) ~ 1), xlab = 't', ylab = 'S')"
  },
  {
    "objectID": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#conclusion",
    "href": "posts/2022-10-25-simulate-time-to-event-data/2022-10-25-simulate-time-to-event-data.html#conclusion",
    "title": "Simulate time to-event-data",
    "section": "Conclusion",
    "text": "Conclusion\nIt is possible to draw survival times defined by an arbitrary hazard function with just a few lines of code. However, the code is not very time-efficient and there might be issues with numerical stability in certain constellations - hence, plausibility of the results needs to be checked manually.\nThe coxed package provides convenient, more sophisticated methods to achieve a similar goal. However, the coxed approach might be more difficult to adapt to specific situations since the code base is more rigid."
  },
  {
    "objectID": "posts/2022-09-08-psychopharmaca-and-time/2022-09-08-psychopharmaca-and-time.html",
    "href": "posts/2022-09-08-psychopharmaca-and-time/2022-09-08-psychopharmaca-and-time.html",
    "title": "Psychopharmaca and time",
    "section": "",
    "text": "library('lattice')\nlibrary('readxl')\n\ndat &lt;- read_excel('Psychopharmaka_Data.xlsx')\n\n\ndat &lt;- dat[order(dat$Jahr), ]\n\n\nstripplot(order(dat$Jahr) ~ Jahr, data = dat, \n          panel = \n            function(x, y, subscripts, ...) {\n              panel.grid(h = -1, v = -1)\n              lsegments(x0 = x, y0 = y - 0.2, \n                        x1 = x, y1 = y - 0.6,\n                        lwd = 3)\n              ltext(x = x, y = y, \n                    labels = dat$Substanz[subscripts])\n              }, \n          xlim = c(1945, 2015), \n          ylab = '')"
  },
  {
    "objectID": "posts/2023-06-08-specifying-mixed-effects-models/2023-06-08-specifying-mixed-effects-models.html",
    "href": "posts/2023-06-08-specifying-mixed-effects-models/2023-06-08-specifying-mixed-effects-models.html",
    "title": "Specifying mixed effects in lme4",
    "section": "",
    "text": "\\(n\\) individuals (\\(i = 1, 2, .., n\\)) are measured \\(m\\) times (\\(j = 1, 2, ..., m\\)) pre-intervention (denoted \\(y_{ij}^{pre}\\)) and post-intervention (denoted \\(y_{ij}^{post}\\))"
  },
  {
    "objectID": "posts/2023-06-08-specifying-mixed-effects-models/2023-06-08-specifying-mixed-effects-models.html#description-of-trial",
    "href": "posts/2023-06-08-specifying-mixed-effects-models/2023-06-08-specifying-mixed-effects-models.html#description-of-trial",
    "title": "Specifying mixed effects in lme4",
    "section": "",
    "text": "\\(n\\) individuals (\\(i = 1, 2, .., n\\)) are measured \\(m\\) times (\\(j = 1, 2, ..., m\\)) pre-intervention (denoted \\(y_{ij}^{pre}\\)) and post-intervention (denoted \\(y_{ij}^{post}\\))"
  },
  {
    "objectID": "posts/2023-06-08-specifying-mixed-effects-models/2023-06-08-specifying-mixed-effects-models.html#underlying-probability-model",
    "href": "posts/2023-06-08-specifying-mixed-effects-models/2023-06-08-specifying-mixed-effects-models.html#underlying-probability-model",
    "title": "Specifying mixed effects in lme4",
    "section": "Underlying probability model",
    "text": "Underlying probability model\n\nNotation\n\n\\(\\beta_0\\) fixed effect intercept\n\\(\\beta_1\\) fixed effect of intervention\n\\(\\epsilon \\sim \\mathcal{N}(\\mu = 0, sd = \\sigma_0)\\), for reasons of better legibility sub- and superscript are omitted here\n\\(b_{1,i}\\) random effect baseline, \\(b_{1,i} \\sim \\mathcal{N}(\\mu = 0, sd = \\sigma_1)\\)\n\\(b_{2,i}\\) random effect of intervention, \\(b_{2,i} \\sim \\mathcal{N}(\\mu = 0, sd = \\sigma_2)\\)\n\n\n\nParameters of the model to be estimated\n\n\\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma_0\\), \\(\\sigma_1\\) and \\(\\sigma_2\\)\n\n\n\nModel equations\n\nMeasurement pre intervention: \\[\\begin{align}\ny_{ij}^{pre} = \\beta_0 + b_i + \\epsilon_{ij}^{pre}\n\\end{align}\\]\nMeasurement post-intervention: \\[\\begin{align}\ny_{ij}^{post} = \\beta_0 + \\beta_1 + b_{1,i} + b_{2,i} + \\epsilon_{ij}^{post}\n\\end{align}\\]\n\n\n\nSimulate data\n\n# size of sample:\nn &lt;- 20\nm &lt;- 5\n\n# model parameters:\nbeta_0 &lt;- 0\nbeta_1 &lt;- 1\nsigma_0 &lt;- 2\nsigma_1 &lt;- 1\nsigma_2 &lt;- 5\n\n# construct data:\npatients &lt;- tibble(patient_id = 1:n, \n                   patient_re = rnorm(n, 0, sigma_1),\n                   treatment_re = rnorm(n, 0, sigma_2))\n\ndat &lt;- expand_grid(patients,\n                   replicate = 1:m,\n                   timepoint = c('pre', 'post'))\n\ndat &lt;- dat |&gt; \n  mutate(y = beta_0 + \n           patient_re + \n           ifelse(timepoint == 'post', treatment_re + beta_1, 0) + \n           rnorm(n * m * 2, 0, sigma_0))\n\n# make timepoint a factor to get order in plots right:\ndat &lt;- dat |&gt; \n  mutate(timepoint = factor(timepoint, levels = c('pre', 'post')))\n\n\n\nTabular characteristics\n\ndat |&gt; \n  group_by(timepoint) |&gt; \n  summarize(mean = mean(y)) |&gt; \n  kable()\n\n\n\n\ntimepoint\nmean\n\n\n\n\npre\n0.1868025\n\n\npost\n1.1930561\n\n\n\n\n\n\n\nVisualize data\n\nif(n &lt; 1e2) {\n  dat |&gt;\n    ggplot(aes(timepoint, y, col = factor(patient_id))) +\n    geom_jitter(width = 0.1, height = 0) + labs(color = 'Patient ID')\n}\n\n\n\n\n\n\nFit model\n\nLinear model\n\n# linear model to get beta_1 and beta_2 \n(fm_lm &lt;- lm(y ~ timepoint, data = dat)) |&gt; summary()\n\n\nCall:\nlm(formula = y ~ timepoint, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.4127  -1.5931   0.0072   2.0727  10.4653 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)     0.1868     0.3489   0.535   0.5930  \ntimepointpost   1.0063     0.4934   2.039   0.0427 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.489 on 198 degrees of freedom\nMultiple R-squared:  0.02057,   Adjusted R-squared:  0.01563 \nF-statistic: 4.159 on 1 and 198 DF,  p-value: 0.04274\n\n\n\n\nMixed effects model with correlation between (Intercept) and timepointpost\n\n(fm_lmer &lt;- lmer(y ~ timepoint + (timepoint | patient_id), data = dat))\n\nboundary (singular) fit: see help('isSingular')\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ timepoint + (timepoint | patient_id)\n   Data: dat\nREML criterion at convergence: 888.5308\nRandom effects:\n Groups     Name          Std.Dev. Corr \n patient_id (Intercept)   0.3268        \n            timepointpost 4.5307   -1.00\n Residual                 1.9086        \nNumber of obs: 200, groups:  patient_id, 20\nFixed Effects:\n  (Intercept)  timepointpost  \n       0.1868         1.0063  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n\n\n\n\nMixed effects model without correlation between (Intercept) and timepointpost\n\nThe specifications I tried seem almost right, but not quite:\n\n\n(fm_lmer &lt;- lmer(y ~ timepoint + (timepoint - 1 || patient_id), data = dat))\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ timepoint + ((0 + timepoint | patient_id))\n   Data: dat\nREML criterion at convergence: 888.5308\nRandom effects:\n Groups     Name          Std.Dev. Corr \n patient_id timepointpre  0.3268        \n            timepointpost 4.2038   -1.00\n Residual                 1.9086        \nNumber of obs: 200, groups:  patient_id, 20\nFixed Effects:\n  (Intercept)  timepointpost  \n       0.1868         1.0063  \n\n(fm_lmer &lt;- lmer(y ~ timepoint + (timepoint - 1 | patient_id), data = dat))\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ timepoint + (timepoint - 1 | patient_id)\n   Data: dat\nREML criterion at convergence: 888.5308\nRandom effects:\n Groups     Name          Std.Dev. Corr \n patient_id timepointpre  0.3268        \n            timepointpost 4.2038   -1.00\n Residual                 1.9086        \nNumber of obs: 200, groups:  patient_id, 20\nFixed Effects:\n  (Intercept)  timepointpost  \n       0.1868         1.0063  \n\n(fm_lmer &lt;- lmer(y ~ timepoint + (1 | patient_id) + (timepoint - 1 | patient_id), data = dat))\n\nboundary (singular) fit: see help('isSingular')\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ timepoint + (1 | patient_id) + (timepoint - 1 | patient_id)\n   Data: dat\nREML criterion at convergence: 888.5308\nRandom effects:\n Groups       Name          Std.Dev. Corr \n patient_id   (Intercept)   0.0000        \n patient_id.1 timepointpre  0.3268        \n              timepointpost 4.2039   -1.00\n Residual                   1.9086        \nNumber of obs: 200, groups:  patient_id, 20\nFixed Effects:\n  (Intercept)  timepointpost  \n       0.1868         1.0063  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n\n(fm_lmer &lt;- lmer(y ~ timepoint + (1 | patient_id) + (timepoint + 0 | patient_id), data = dat))\n\nboundary (singular) fit: see help('isSingular')\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ timepoint + (1 | patient_id) + (timepoint + 0 | patient_id)\n   Data: dat\nREML criterion at convergence: 888.5308\nRandom effects:\n Groups       Name          Std.Dev. Corr \n patient_id   (Intercept)   0.0000        \n patient_id.1 timepointpre  0.3268        \n              timepointpost 4.2039   -1.00\n Residual                   1.9086        \nNumber of obs: 200, groups:  patient_id, 20\nFixed Effects:\n  (Intercept)  timepointpost  \n       0.1868         1.0063  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings"
  },
  {
    "objectID": "posts/2022-07-19-sir-model/2022-07-19-sir-model.html",
    "href": "posts/2022-07-19-sir-model/2022-07-19-sir-model.html",
    "title": "SIR model",
    "section": "",
    "text": "Here I want to show some sample calculations using the SIR model (https://simple.wikipedia.org/wiki/SIR_model, https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology).\nThe SIR model is a simple ordinary differential equation model that describes the dynamics of an epidemic within a population. The model has three variables:\n\n\\(S\\) (= susceptible) quantifies the susceptible individuals\n\\(I\\) (= infectious) quantifies the individuals who are infected with the disease and can transmit the disease to susceptible individuals\n\\(R\\) (= recovered) quantifies the individuals who have recovered from the disease and can no longer be infected with the disease\n\nThe following equations describe the dynamics of the model: \\[ \\frac{dS}{dt} = -\\frac{\\beta I S}{N} \\]\n\\[ \\frac{dI}{dt} = \\frac{\\beta I S}{N} - \\lambda I \\]\n\\[ \\frac{dR}{dt} = \\lambda I \\]\nIn the following, we solve the model equations for a random parameter set.\nFurthermore, we fix \\(N\\) to \\(1\\) and set the initial conditions in a way that \\(S + I + R = 1\\) so that \\(S\\), \\(R\\) and \\(I\\) describe fractions of the population.\n\nparameters &lt;- c(beta = 2, \n                gamma = 1)\n\ninfected_initial &lt;- 0.01\ninitial_condition &lt;- \n  c(S = 1 - infected_initial,\n    I = infected_initial,\n    R = 0)\n\ntimepoints &lt;- seq(0, 15, by = .1)\n\nThen we define the model equations in R:\n\nSIR_ODE = function(time, state, parameters){\n  with(as.list(c(state, parameters)), {\n    dS &lt;- -beta * I * S\n    dI &lt;- beta * I * S - gamma * I\n    dR &lt;- gamma * I\n    list(c(dS, dI, dR))\n    })\n  }\n\nFinally, we use the function ode from the deSolve package to solve the ordinary differential equations:\n\nlibrary(deSolve)\nresult &lt;- ode(y = initial_condition, \n             times = timepoints, \n             func = SIR_ODE, \n             parms = parameters)\n\nNow we use the builtin plot function from the deSolve-package to visualize the solution:\n\nplot(result)\n\n\n\n\nWe can make some plots that are nicer looking in my taste with the lattice package. To rearrange the data from ‘wide’ to ‘long’ format (as needed for the lattice package), we use the tidyverse package.\n\nlibrary(lattice)\nlibrary(tidyverse)\ntheme_set(theme_bw())\n\n# convert data from wide to long format:\nlong &lt;- as.data.frame(result) %&gt;% \n  pivot_longer(cols = c('S', 'I', 'R'))\n\n# order factor levels so they appear in the plots in the desired order:\nlong$name = factor(long$name, levels = c('S', 'I', 'R'))\n\n# plot all three variables in the same panel:\nxyplot(value ~ time, \n       data = long, \n       group = name, \n       auto.key = list(space = 'right', \n                       lines = TRUE, \n                       points = FALSE), \n       type = 'l',\n       lwd = 3)\n\n\n\n# plot the variables in separate panels:\nxyplot(value ~ time | name, \n       data = long, \n       type = 'l', \n       lwd = 3)\n\n\n\n\nVery similar plots can be made with the ggplot2 library:\n\nlong %&gt;% ggplot(aes(time, value, colour = name)) + \n  geom_line(size = 2) + \n  labs(x = 'Time', y = 'Fraction', colour = 'Compartment')\n\n\n\nlong %&gt;% ggplot(aes(time, value)) + \n  geom_line(size = 2) +\n  facet_wrap(~ name) +\n  labs(x = 'Time', y = 'Fraction', colour = 'Compartment')"
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "",
    "text": "Here, an model based on the SIR model is presented in a deterministic version and in a non-deterministic version. For solving the ODEs (deterministic version) and the stochastic difference equations (stochastic version), the R package deSolve is used."
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#summary",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#summary",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "",
    "text": "Here, an model based on the SIR model is presented in a deterministic version and in a non-deterministic version. For solving the ODEs (deterministic version) and the stochastic difference equations (stochastic version), the R package deSolve is used."
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#defining-and-solving-a-simple-ode-model",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#defining-and-solving-a-simple-ode-model",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "Defining and solving a simple ODE model",
    "text": "Defining and solving a simple ODE model\nA simplified SIR model: \\[ \\frac{dS}{dt} = -\\frac{\\beta I S}{N} \\]\n\\[ \\frac{dI}{dt} = \\frac{\\beta I S}{N} - \\gamma I \\]\n\\[ \\frac{dR}{dt} = \\gamma I \\]"
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#loading-the-required-libraries-and-defining-utility-functions",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#loading-the-required-libraries-and-defining-utility-functions",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "Loading the required libraries and defining utility functions",
    "text": "Loading the required libraries and defining utility functions\n\nlibrary('ggplot2')\nlibrary('tidyverse')\nlibrary('deSolve')\ntheme_set(theme_bw())\n\n\nplot_deSolve_result &lt;- function(result) {\n  tib &lt;- as_tibble(unclass(result))  \n  vars &lt;- colnames(result)[-1]\n  long &lt;- pivot_longer(tib, cols = all_of(vars))\n  long$name &lt;- factor(long$name, levels = c('S', 'I', 'R'))\n  ggplot(long, aes(time, value, colour = name)) + \n    geom_line() + \n    labs(colour = 'Compartment', \n         x = 'Time',\n         y = 'Fraction')\n}"
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#definition-of-the-parameters",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#definition-of-the-parameters",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "Definition of the parameters",
    "text": "Definition of the parameters\n\nparameters &lt;- list(beta = 0.2, \n                   gamma = .01,\n                   lambda = 0)\n\ninfected_initial &lt;- 0.01\ninitial_condition &lt;- \n  c(S = 1 - infected_initial,\n    I = infected_initial,\n    R = 0)\n\nt_max &lt;- 100\nstep_length &lt;- t_max / 100\ntimepoints &lt;- seq(0, 150, length.out = 100)"
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#deterministic-model",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#deterministic-model",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "Deterministic model",
    "text": "Deterministic model\n\nsir_ode_deterministic &lt;- function(t, state, pars) {\n  with(as.list(c(state, pars)), {\n    dS &lt;- - beta * I * S + lambda * R\n    dI &lt;- beta * I * S - gamma * I\n    dR &lt;- gamma * I - lambda * R\n    return(list(c(dS = dS, dI = dI, dR = dR)))\n  }) \n}\n\n\nsir_solution_deterministic &lt;- \n  ode(y = initial_condition, \n      times = timepoints,\n      func = sir_ode_deterministic,\n      parms = parameters)\nplot_deSolve_result(sir_solution_deterministic)"
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#stochastic-model",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#stochastic-model",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "Stochastic model",
    "text": "Stochastic model\n\nsir_ode_stochastic &lt;- function(t, state, pars) {\n  with(as.list(c(state, pars)), {\n    S_new &lt;- S - beta * I * S * step_length\n    I_new &lt;- I + (beta * I * S - gamma * I) * step_length\n    R_new &lt;- R + gamma * I * step_length\n    \n    new_values &lt;-c(S = S_new, I = I_new, R = R_new)\n    new_values &lt;- new_values * rlnorm(3, meanlog = 0, sdlog = 0.05)\n    new_values &lt;- new_values / sum(new_values)\n    return(list(new_values))\n  })\n}\n\nsir_solution_stochastic &lt;- \n  ode(y = initial_condition, \n      times = timepoints,\n      func = sir_ode_stochastic,\n      parms = parameters, \n      method = 'iteration')\n\nplot_deSolve_result(sir_solution_stochastic)"
  },
  {
    "objectID": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#conclusion",
    "href": "posts/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version/2022-10-04-sir-like-model-with-desolve-in-deterministic-and-stochastic-version.html#conclusion",
    "title": "SIR-like model with deSolve in deterministic and stochastic version",
    "section": "Conclusion",
    "text": "Conclusion\nThe R package deSolve can be used to solve deterministic ODEs and stochastic difference equations."
  },
  {
    "objectID": "posts/2023-07-12-model-diagnostics-for-logistic-regression/2023-07-12-model-diagnostics-for-logistic-regression.html",
    "href": "posts/2023-07-12-model-diagnostics-for-logistic-regression/2023-07-12-model-diagnostics-for-logistic-regression.html",
    "title": "Model diagnostics for logistic regression",
    "section": "",
    "text": "library('tidyverse')\nlibrary('faraway')\nset.seed(1)\n\n\nn &lt;- 100\ndat &lt;- tibble(x1 = rnorm(n), \n              x2 = rnorm(n),\n              x3 = rnorm(n),)\n\nX &lt;- model.matrix(~ ., data = dat)\nbeta &lt;- rnorm(ncol(X))\n\n\n\ndat &lt;- dat |&gt; \n  mutate(mu = X %*% beta,\n         p = plogis(mu),\n         result = rbinom(n, 1, p))\n\nfitted_model &lt;- glm(result ~ x1 + x2 + x3, data = dat, family = binomial())\n\nplot(fitted_model)\n\n\n\n\n\n\n\n\n\n\n\n\nprplot(fitted_model, 1)\n\n\n\nprplot(fitted_model, 2)\n\n\n\nprplot(fitted_model, 3)"
  },
  {
    "objectID": "posts/2022-09-08-timeline/2022-09-08-timeline.html",
    "href": "posts/2022-09-08-timeline/2022-09-08-timeline.html",
    "title": "Timeline",
    "section": "",
    "text": "format_ods_data_frame &lt;- \n  function(dat, \n           colnames = TRUE, \n           type_definition = TRUE) {\n    \n    result &lt;- dat\n    \n    if (colnames) {\n      result &lt;- result[-1, ]\n      colnames(result) &lt;- dat[1, ]\n    }\n    \n    if (type_definition) {\n      type_defs &lt;- result[1, ]\n      result &lt;- result[-1, ]\n      for (i in 1:ncol(dat)) {\n        if (type_defs[i] == 'Factor') {\n          result[result[, i] == '', i] &lt;- NA\n          result[, i] &lt;- as.factor(result[, i])  \n        }\n        if (type_defs[i] == 'Numeric')\n          result[, i] &lt;- as.numeric(result[, i])\n        if (type_defs[i] == 'Character')\n          result[, i] &lt;- as.character(result[, i])\n      }\n    }\n    rownames(result) &lt;- NULL\n    return(result)\n  }\n\nplot_timeline &lt;- function(label,\n                          begin, \n                          end, \n                          group = NULL) {\n  n &lt;- length(label)\n  if(is.null(group)) {\n    group &lt;- 1:n\n  } else {\n    group &lt;- as.numeric(group)\n  }\n  timeline_colors &lt;- rainbow(max(group), \n                             s = 0.1)\n  par(mar = c(3.1, 2.1, 2.1, 2.1))\n  plot(0, type = 'n',\n       ylab = '', xlab = '', yaxt = 'n',\n       ylim = c(n, 0), \n       xlim = range(begin, end))\n  grid()\n  rect(xleft = begin,\n       xright = end,\n       ybottom = 0:(n - 1) + 0.1,\n       ytop = 1:n - 0.1,\n       col = timeline_colors[group])\n  text((begin + end) / 2,\n       1:n - 0.5,\n       label)\n}\n\n\nlibrary('readODS')\nModernism &lt;- format_ods_data_frame(\n  read.ods('Art_Modernism.ods', \n           sheet = 1))\n\nWarning in read.ods(\"Art_Modernism.ods\", sheet = 1): read.ods will be\ndeprecated in the next version. Use read_ods instead.\n\n\n\npar(mar = c(3.1, 2.1, 2.1, 2.1))\nplot(0, type = 'n',\n     ylab = '', xlab = '', yaxt = 'n',\n     ylim = c(nrow(Modernism), 0), \n     xlim = range(Modernism$Begin, Modernism$End))\ngrid()\nrect(xleft = Modernism$Begin,\n     xright = Modernism$End,\n     ybottom = 0:(nrow(Modernism) - 1) + 0.1,\n     ytop = 1:nrow(Modernism) - 0.1,\n     col = rainbow(nrow(Modernism), \n                   s = 0.2))\ntext((Modernism$Begin + Modernism$End) / 2,\n     1:nrow(Modernism) - 0.5,\n     Modernism$Label)\n\n\n\n\n\npainters &lt;- format_ods_data_frame(\n  read.ods('Painters.ods', sheet = 1))\n\nWarning in read.ods(\"Painters.ods\", sheet = 1): read.ods will be deprecated in\nthe next version. Use read_ods instead.\n\nwith(painters, \n     plot_timeline(Label, Begin, End, group = Group))"
  },
  {
    "objectID": "posts/2023-01-05-contribution-plots/2023-01-05-contribution-plots.html",
    "href": "posts/2023-01-05-contribution-plots/2023-01-05-contribution-plots.html",
    "title": "Contribution plots",
    "section": "",
    "text": "library('tibble')\nlibrary('ggplot2')\nlibrary('RColorBrewer')\nlibrary('plotly')\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ntheme_set(theme_minimal())\n#help(package = 'RColorBrewer')\nnr_of_clones &lt;- 11\nnr_of_timepoins &lt;- 20\n\ndat &lt;- tibble(t = rep(1:nr_of_timepoins, each = nr_of_clones),\n              p = abs(rnorm(nr_of_clones * nr_of_timepoins)),\n              s = rep(1:nr_of_clones, nr_of_timepoins))\n\ndat$p &lt;- dat$p / rep(tapply(dat$p, dat$t, sum), each = nr_of_clones)\n\n# my_cols &lt;- rainbow(nr_of_clones)\nmy_cols &lt;- brewer.pal(nr_of_clones, 'Spectral')\n\n(g &lt;- ggplot(dat, aes(x = t, y = p, group = factor(s), fill = factor(s))) + \n  geom_area(alpha = 0.65) + \n  scale_fill_manual(name = 'State', values = my_cols) +\n  xlab('Time') + ylab('Relative contibution'))\n\n\n\n# ggplotly(g)"
  },
  {
    "objectID": "posts/2023-01-05-contribution-plots/2023-01-05-contribution-plots.html#contribution-plot-using-ggplot2-and-plotly",
    "href": "posts/2023-01-05-contribution-plots/2023-01-05-contribution-plots.html#contribution-plot-using-ggplot2-and-plotly",
    "title": "Contribution plots",
    "section": "",
    "text": "library('tibble')\nlibrary('ggplot2')\nlibrary('RColorBrewer')\nlibrary('plotly')\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ntheme_set(theme_minimal())\n#help(package = 'RColorBrewer')\nnr_of_clones &lt;- 11\nnr_of_timepoins &lt;- 20\n\ndat &lt;- tibble(t = rep(1:nr_of_timepoins, each = nr_of_clones),\n              p = abs(rnorm(nr_of_clones * nr_of_timepoins)),\n              s = rep(1:nr_of_clones, nr_of_timepoins))\n\ndat$p &lt;- dat$p / rep(tapply(dat$p, dat$t, sum), each = nr_of_clones)\n\n# my_cols &lt;- rainbow(nr_of_clones)\nmy_cols &lt;- brewer.pal(nr_of_clones, 'Spectral')\n\n(g &lt;- ggplot(dat, aes(x = t, y = p, group = factor(s), fill = factor(s))) + \n  geom_area(alpha = 0.65) + \n  scale_fill_manual(name = 'State', values = my_cols) +\n  xlab('Time') + ylab('Relative contibution'))\n\n\n\n# ggplotly(g)"
  },
  {
    "objectID": "posts/2023-01-05-contribution-plots/2023-01-05-contribution-plots.html#another-plotly-plot",
    "href": "posts/2023-01-05-contribution-plots/2023-01-05-contribution-plots.html#another-plotly-plot",
    "title": "Contribution plots",
    "section": "Another plotly plot",
    "text": "Another plotly plot\n\n(g &lt;- ggplot(cars, aes(dist, speed)) + geom_point())\n\n\n\n# ggplotly(g)"
  },
  {
    "objectID": "posts/2023-07-06-python-versions-environments/2023-07-06-python-versions-environments.html",
    "href": "posts/2023-07-06-python-versions-environments/2023-07-06-python-versions-environments.html",
    "title": "Managing python versions in RStudio",
    "section": "",
    "text": "Ressources\n\nGood resources are found in the {reticulate} vignettes: Link, in particular this\n\n\n\nManaging python installation\n\nlibrary('reticulate')\npy_discover_config()\npy_config()\nconda_list()\n\nconda_version()\nconfigure_environment()\nconda_create('sbloggel')\n\n\nconda_install('sbloggel', 'pandas')\nminiconda_update()\nuse_condaenv('sbloggel')\nconda_install('sbloggel', 'plotly')\nuse_condaenv('base')\n\n\n\nInstall virtual environments to jupyter\n\nLink\n\n\n# Prepare python to enable installation of virtual environments in Jupyter:\npip install --user ipykernel\n\n# Show conda environments and activate:\nconda info --envs  \nconda activate sbloggel\n\n# Install virtual environment into jupyter:\npython -m ipykernel install --user --name=sbloggel\nconda activate /Users/seb/Library/r-miniconda-arm64/envs/sbloggel  \n\nStart Jupyter from terminal:\n\njupyter notebook"
  },
  {
    "objectID": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html",
    "href": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html",
    "title": "R interfaces to trial registries",
    "section": "",
    "text": "library('tidyverse')\n\nlibrary('ggVennDiagram')\nlibrary('clinicaltrialr') \n\nresults_q_twist &lt;- ct_read_results('https://www.clinicaltrials.gov/ct2/results?cond=&term=Q-TWiST&type=&rslt=&age_v=&gndr=&intr=&titles=&outc=&spons=&lead=&id=&cntry=&state=&city=&dist=&locn=&rsub=&strd_s=&strd_e=&prcd_s=&prcd_e=&sfpd_s=&sfpd_e=&rfpd_s=&rfpd_e=&lupd_s=&lupd_e=&sort=')\nresults_qas &lt;- ct_read_results('https://www.clinicaltrials.gov/ct2/results?cond=&term=%22quality+adjusted+survival%22&type=&rslt=&age_v=&gndr=&intr=&titles=&outc=&spons=&lead=&id=&cntry=&state=&city=&dist=&locn=&rsub=&strd_s=&strd_e=&prcd_s=&prcd_e=&sfpd_s=&sfpd_e=&rfpd_s=&rfpd_e=&lupd_s=&lupd_e=&sort=')\n\nstr(results_qas)\n\n# List of items\nx &lt;- list('Keyword \"Quality-adjusted survival\"' = results_qas$`NCT Number`, \n          'Keyword \"Q-TWiST\"' = results_q_twist$`NCT Number`)\n\n# 2D Venn diagram\nggVennDiagram(x) + theme(legend.position = 'none')"
  },
  {
    "objectID": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html#package-clinicaltrialr",
    "href": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html#package-clinicaltrialr",
    "title": "R interfaces to trial registries",
    "section": "",
    "text": "library('tidyverse')\n\nlibrary('ggVennDiagram')\nlibrary('clinicaltrialr') \n\nresults_q_twist &lt;- ct_read_results('https://www.clinicaltrials.gov/ct2/results?cond=&term=Q-TWiST&type=&rslt=&age_v=&gndr=&intr=&titles=&outc=&spons=&lead=&id=&cntry=&state=&city=&dist=&locn=&rsub=&strd_s=&strd_e=&prcd_s=&prcd_e=&sfpd_s=&sfpd_e=&rfpd_s=&rfpd_e=&lupd_s=&lupd_e=&sort=')\nresults_qas &lt;- ct_read_results('https://www.clinicaltrials.gov/ct2/results?cond=&term=%22quality+adjusted+survival%22&type=&rslt=&age_v=&gndr=&intr=&titles=&outc=&spons=&lead=&id=&cntry=&state=&city=&dist=&locn=&rsub=&strd_s=&strd_e=&prcd_s=&prcd_e=&sfpd_s=&sfpd_e=&rfpd_s=&rfpd_e=&lupd_s=&lupd_e=&sort=')\n\nstr(results_qas)\n\n# List of items\nx &lt;- list('Keyword \"Quality-adjusted survival\"' = results_qas$`NCT Number`, \n          'Keyword \"Q-TWiST\"' = results_q_twist$`NCT Number`)\n\n# 2D Venn diagram\nggVennDiagram(x) + theme(legend.position = 'none')"
  },
  {
    "objectID": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html#package-rclinicaltrials",
    "href": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html#package-rclinicaltrials",
    "title": "R interfaces to trial registries",
    "section": "Package ‘rclinicaltrials’",
    "text": "Package ‘rclinicaltrials’\n\nlibrary(rclinicaltrials)\n# z &lt;- clinicaltrials_search(query = 'lime+disease') \n# str(z)\nclinicaltrials_count(query = \"myeloma\") \nclinicaltrials_count(query = \"29485tksrw@\")\n\ny &lt;- clinicaltrials_download(query = 'myeloma', count = 10, include_results = TRUE)\nstr(y)"
  },
  {
    "objectID": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html#package-cthist",
    "href": "posts/2022-11-24-r-interfaces-to-trial-registries/2022-11-24-r-interfaces-to-trial-registries.html#package-cthist",
    "title": "R interfaces to trial registries",
    "section": "Package ‘cthist’",
    "text": "Package ‘cthist’\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC9249399/\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(cthist)\nlibrary(lubridate)"
  },
  {
    "objectID": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html",
    "href": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html",
    "title": "The iris dataset",
    "section": "",
    "text": "library('tidyverse')\nlibrary('lme4')"
  },
  {
    "objectID": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#init",
    "href": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#init",
    "title": "The iris dataset",
    "section": "",
    "text": "library('tidyverse')\nlibrary('lme4')"
  },
  {
    "objectID": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#data-preparation",
    "href": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#data-preparation",
    "title": "The iris dataset",
    "section": "Data preparation",
    "text": "Data preparation\n\niris_long &lt;- iris |&gt; \n  mutate(id = 1:nrow(iris)) |&gt; \n  pivot_longer(cols = -c(Species, id), \n               names_to = 'Variable', \n               values_to = 'Value')"
  },
  {
    "objectID": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#plots",
    "href": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#plots",
    "title": "The iris dataset",
    "section": "Plots",
    "text": "Plots\n\niris_long |&gt; \n  ggplot(aes(Variable, Value, color = Species)) + \n  geom_boxplot()\n\n\n\nlast_plot() + scale_y_log10() \n\n\n\niris_long |&gt; \n  ggplot(aes(Variable, Value, color = Species)) + \n  geom_jitter(height = 0)\n\n\n\nlast_plot() + scale_y_log10()"
  },
  {
    "objectID": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#models",
    "href": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#models",
    "title": "The iris dataset",
    "section": "Models",
    "text": "Models\n\nfitted_model &lt;- \n  lm(Value ~ Species * Variable, \n     data = iris_long)\nanova(fitted_model)\n\nAnalysis of Variance Table\n\nResponse: Value\n                  Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nSpecies            2  309.61  154.80 1019.34 &lt; 2.2e-16 ***\nVariable           3 1656.26  552.09 3635.35 &lt; 2.2e-16 ***\nSpecies:Variable   6  282.47   47.08  309.99 &lt; 2.2e-16 ***\nResiduals        588   89.30    0.15                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(fitted_model)\n\n\n\n\n\n\n\n\n\n\n\n\nfitted_model &lt;- \n  lm(log(Value) ~ Species * Variable, \n     data = iris_long)\nanova(fitted_model)\n\nAnalysis of Variance Table\n\nResponse: log(Value)\n                  Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nSpecies            2  90.843  45.421 1772.90 &lt; 2.2e-16 ***\nVariable           3 297.393  99.131 3869.31 &lt; 2.2e-16 ***\nSpecies:Variable   6  95.977  15.996  624.37 &lt; 2.2e-16 ***\nResiduals        588  15.064   0.026                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(fitted_model)\n\n\n\n\n\n\n\n\n\n\n\n\nfitted_model &lt;- \n  lmer(log(Value) ~ Species * Variable + (1 | id),\n     data = iris_long)\nfitted_model\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: log(Value) ~ Species * Variable + (1 | id)\n   Data: iris_long\nREML criterion at convergence: -496.6563\nRandom effects:\n Groups   Name        Std.Dev.\n id       (Intercept) 0.08565 \n Residual             0.13522 \nNumber of obs: 600, groups:  id, 150\nFixed Effects:\n                           (Intercept)                       Speciesversicolor  \n                                0.3728                                  1.0702  \n                      Speciesvirginica                     VariablePetal.Width  \n                                1.3367                                 -1.8574  \n                  VariableSepal.Length                     VariableSepal.Width  \n                                1.2354                                  0.8531  \n Speciesversicolor:VariablePetal.Width    Speciesvirginica:VariablePetal.Width  \n                                0.6854                                  0.8447  \nSpeciesversicolor:VariableSepal.Length   Speciesvirginica:VariableSepal.Length  \n                               -0.9011                                 -1.0642  \n Speciesversicolor:VariableSepal.Width    Speciesvirginica:VariableSepal.Width  \n                               -1.2837                                 -1.4783"
  },
  {
    "objectID": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#conclusion",
    "href": "posts/2023-07-12-the-iris-dataset/2023-07-12-the-iris-dataset.html#conclusion",
    "title": "The iris dataset",
    "section": "Conclusion",
    "text": "Conclusion\n\nIn general, I like the log scale modeling - however there is a problem with the model on log scale\n\nEffects can be given as fold-changes - this seems to make sense to me\nSpecies “setosa” is not fit adequately on log scale - probably measurement error is not adequately modeled on log scale - higher variance of error on log scale"
  },
  {
    "objectID": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html",
    "href": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html",
    "title": "Exploring the Python library statsmodels",
    "section": "",
    "text": "Link\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport statsmodels.api as sm\n\ndata = sm.datasets.statecrime.load_pandas().data\nmurder = data['murder']\nX = data[['poverty', 'hs_grad']].copy()\nX['constant'] = 1\n\ny = murder\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n# Create a plot just for the variable 'Poverty':\n\nfig, ax = plt.subplots()\nfig = sm.graphics.plot_fit(results, 0, ax=ax)\nax.set_ylabel(\"Murder Rate\")\nax.set_xlabel(\"Poverty Level\")\nax.set_title(\"Linear Regression\")\n\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_fit",
    "href": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_fit",
    "title": "Exploring the Python library statsmodels",
    "section": "",
    "text": "Link\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport statsmodels.api as sm\n\ndata = sm.datasets.statecrime.load_pandas().data\nmurder = data['murder']\nX = data[['poverty', 'hs_grad']].copy()\nX['constant'] = 1\n\ny = murder\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n# Create a plot just for the variable 'Poverty':\n\nfig, ax = plt.subplots()\nfig = sm.graphics.plot_fit(results, 0, ax=ax)\nax.set_ylabel(\"Murder Rate\")\nax.set_xlabel(\"Poverty Level\")\nax.set_title(\"Linear Regression\")\n\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_regress_exog",
    "href": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_regress_exog",
    "title": "Exploring the Python library statsmodels",
    "section": "plot_regress_exog",
    "text": "plot_regress_exog\n\nLink\n\n\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n\n\nfig = plt.figure(figsize=(8, 6))\ncrime_data = sm.datasets.statecrime.load_pandas()\nresults = smf.ols('murder ~ hs_grad + urban + poverty + single',\n                   data=crime_data.data).fit()\nsm.graphics.plot_regress_exog(results, 'poverty', fig=fig)\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_partregress",
    "href": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_partregress",
    "title": "Exploring the Python library statsmodels",
    "section": "plot_partregress",
    "text": "plot_partregress\n\nLink\n\n\ncrime_data = sm.datasets.statecrime.load_pandas()\nsm.graphics.plot_partregress(endog='murder', exog_i='hs_grad',\n                              exog_others=['urban', 'poverty', 'single'],\n                              data=crime_data.data, obs_labels=False)\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_partregress_grid",
    "href": "posts/2023-07-04-python-statsmodels/2023-07-04-python-statsmodels.html#plot_partregress_grid",
    "title": "Exploring the Python library statsmodels",
    "section": "plot_partregress_grid",
    "text": "plot_partregress_grid\n\nLink\n\n\nimport matplotlib.pyplot as plt\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.graphics.regressionplots import plot_partregress_grid\n\nfig = plt.figure(figsize=(8, 6))\ncrime_data = sm.datasets.statecrime.load_pandas()\nresults = smf.ols('murder ~ hs_grad + urban + poverty + single',\n                  data=crime_data.data).fit()\nplot_partregress_grid(results, fig=fig)\nplt.show()\n\n\n\n\n\nimport statsmodels.api as sm\nimport pandas\ndf = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n\nfm = sm.formula.ols('Lottery ~ Literacy + Wealth + C(Region)', data = df).fit()\nprint(fm.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                Lottery   R-squared:                       0.338\nModel:                            OLS   Adj. R-squared:                  0.287\nMethod:                 Least Squares   F-statistic:                     6.636\nDate:                Mon, 10 Jul 2023   Prob (F-statistic):           1.07e-05\nTime:                        10:37:19   Log-Likelihood:                -375.30\nNo. Observations:                  85   AIC:                             764.6\nDf Residuals:                      78   BIC:                             781.7\nDf Model:                           6                                         \nCovariance Type:            nonrobust                                         \n==================================================================================\n                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nIntercept         38.6517      9.456      4.087      0.000      19.826      57.478\nC(Region)[T.E]   -15.4278      9.727     -1.586      0.117     -34.793       3.938\nC(Region)[T.N]   -10.0170      9.260     -1.082      0.283     -28.453       8.419\nC(Region)[T.S]    -4.5483      7.279     -0.625      0.534     -19.039       9.943\nC(Region)[T.W]   -10.0913      7.196     -1.402      0.165     -24.418       4.235\nLiteracy          -0.1858      0.210     -0.886      0.378      -0.603       0.232\nWealth             0.4515      0.103      4.390      0.000       0.247       0.656\n==============================================================================\nOmnibus:                        3.049   Durbin-Watson:                   1.785\nProb(Omnibus):                  0.218   Jarque-Bera (JB):                2.694\nSkew:                          -0.340   Prob(JB):                        0.260\nKurtosis:                       2.454   Cond. No.                         371.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nfig = sm.graphics.influence_plot(fm, criterion=\"cooks\")\nfig.show()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme(style=\"whitegrid\")\n\n# Load the example diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Draw a scatter plot while assigning point colors and sizes to different\n# variables in the dataset\nf, ax = plt.subplots(figsize=(6.5, 6.5))\nsns.despine(f, left=True, bottom=True)\nclarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(x=\"carat\", y=\"price\",\n                hue=\"clarity\", size=\"depth\",\n                palette=\"ch:r=-.2,d=.3_r\",\n                hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=diamonds, ax=ax)"
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "",
    "text": "The COVID19 package allows to conveniently retrieve statistical data about the COVID-19 pandemy. Here, the data for Germany are retrieved and two exploratory plots are created."
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#background",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#background",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "",
    "text": "The COVID19 package allows to conveniently retrieve statistical data about the COVID-19 pandemy. Here, the data for Germany are retrieved and two exploratory plots are created."
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#loading-libraries",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#loading-libraries",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "Loading libraries",
    "text": "Loading libraries\n\nlibrary('ggplot2')\nlibrary('COVID19')"
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#retrieving-the-data",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#retrieving-the-data",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "Retrieving the data",
    "text": "Retrieving the data\n\ndeu &lt;- covid19('Germany', level = 1) \n\nWe have invested a lot of time and effort in creating COVID-19 Data\nHub, please cite the following when using it:\n\n  Guidotti, E., Ardia, D., (2020), \"COVID-19 Data Hub\", Journal of Open\n  Source Software 5(51):2376, doi: 10.21105/joss.02376\n\nThe implementation details and the latest version of the data are\ndescribed in:\n\n  Guidotti, E., (2022), \"A worldwide epidemiological database for\n  COVID-19 at fine-grained spatial resolution\", Sci Data 9(1):112, doi:\n  10.1038/s41597-022-01245-1\nTo print citations in BibTeX format use:\n &gt; print(citation('COVID19'), bibtex=TRUE)\n\nTo hide this message use 'verbose = FALSE'."
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#plotting-total-number-of-confirmed-cases",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#plotting-total-number-of-confirmed-cases",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "Plotting total number of confirmed cases",
    "text": "Plotting total number of confirmed cases\n\nggplot(data = deu, aes(date, confirmed)) + geom_point() + \n  geom_smooth()  + scale_y_log10()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 12 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#plotting-new-cases",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#plotting-new-cases",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "Plotting new cases",
    "text": "Plotting new cases\n\ndat &lt;- data.frame(date = deu$date[-1], new_cases = diff(deu$confirmed))\nggplot(data = dat, aes(date, new_cases)) + geom_point() + \n  geom_smooth()  + scale_y_log10()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 19 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 19 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#conclusion",
    "href": "posts/2022-10-16-retrieving-and-plotting-covid-19-data/2022-10-16-retrieving-and-plotting-covid-19-data.html#conclusion",
    "title": "Retrieving and plotting COVID-19 data",
    "section": "Conclusion",
    "text": "Conclusion\nThis package allows convenient retrieval of a lot of data about the COVID-19 pandemy."
  },
  {
    "objectID": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html",
    "href": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html",
    "title": "Interesting R packages",
    "section": "",
    "text": "Flow charts in R: ggflowchart\nWeb scraping: rvest\nSpatial data / maps: Recommendations from Nicola Rennie’s blog"
  },
  {
    "objectID": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#short-notes-about-r-packages",
    "href": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#short-notes-about-r-packages",
    "title": "Interesting R packages",
    "section": "",
    "text": "Flow charts in R: ggflowchart\nWeb scraping: rvest\nSpatial data / maps: Recommendations from Nicola Rennie’s blog"
  },
  {
    "objectID": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#check-package-names",
    "href": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#check-package-names",
    "title": "Interesting R packages",
    "section": "Check package names",
    "text": "Check package names\n\n\n── merge ───────────────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✔ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✔ \nAbbreviations: http://www.abbreviations.com/merge\nWikipedia: https://en.wikipedia.org/wiki/merge\nWiktionary: https://en.wiktionary.org/wiki/merge\nSentiment:???\n\n\n── track ───────────────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✖ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✔ \nAbbreviations: http://www.abbreviations.com/track\nWikipedia: https://en.wikipedia.org/wiki/track\nWiktionary: https://en.wiktionary.org/wiki/track\nSentiment:???\n\n\n── trackChanges ────────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✔ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✔ \nAbbreviations: http://www.abbreviations.com/track\nWikipedia: https://en.wikipedia.org/wiki/track\nWiktionary: https://en.wiktionary.org/wiki/track\nSentiment:???\nAbbreviations: http://www.abbreviations.com/Changes\nWikipedia: https://en.wikipedia.org/wiki/Changes\nWiktionary: https://en.wiktionary.org/wiki/Changes\nSentiment:???\nAbbreviations: http://www.abbreviations.com/trackC\nWikipedia: https://en.wikipedia.org/wiki/trackC\nWiktionary: https://en.wiktionary.org/wiki/trackC\nSentiment:???\nAbbreviations: http://www.abbreviations.com/hanges\nWikipedia: https://en.wikipedia.org/wiki/hanges\nWiktionary: https://en.wiktionary.org/wiki/hanges\nSentiment:???\nAbbreviations: http://www.abbreviations.com/trackChanges\nWikipedia: https://en.wikipedia.org/wiki/trackChanges\nWiktionary: https://en.wiktionary.org/wiki/trackChanges\nSentiment:???\n\n\n── trackR ──────────────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✖ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✖ \nAbbreviations: http://www.abbreviations.com/track\nWikipedia: https://en.wikipedia.org/wiki/track\nWiktionary: https://en.wiktionary.org/wiki/track\nSentiment:???\n\n\n── collab ──────────────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✔ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✔ \nAbbreviations: http://www.abbreviations.com/collab\nWikipedia: https://en.wikipedia.org/wiki/collab\nWiktionary: https://en.wiktionary.org/wiki/collab\nSentiment:???\n\n\n── writeTogether ───────────────────────────────────────────────────────────────\nName valid: ✔\nAvailable on CRAN: ✔ \nAvailable on Bioconductor: ✔\nAvailable on GitHub:  ✔ \nAbbreviations: http://www.abbreviations.com/write\nWikipedia: https://en.wikipedia.org/wiki/write\nWiktionary: https://en.wiktionary.org/wiki/write\nSentiment:???\nAbbreviations: http://www.abbreviations.com/Together\nWikipedia: https://en.wikipedia.org/wiki/Together\nWiktionary: https://en.wiktionary.org/wiki/Together\nSentiment:???\nAbbreviations: http://www.abbreviations.com/writeT\nWikipedia: https://en.wikipedia.org/wiki/writeT\nWiktionary: https://en.wiktionary.org/wiki/writeT\nSentiment:???\nAbbreviations: http://www.abbreviations.com/ogether\nWikipedia: https://en.wikipedia.org/wiki/ogether\nWiktionary: https://en.wiktionary.org/wiki/ogether\nSentiment:???\nAbbreviations: http://www.abbreviations.com/writeTogether\nWikipedia: https://en.wikipedia.org/wiki/writeTogether\nWiktionary: https://en.wiktionary.org/wiki/writeTogether\nSentiment:???"
  },
  {
    "objectID": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#r-packages-built-from-a-single-.rmd-file",
    "href": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#r-packages-built-from-a-single-.rmd-file",
    "title": "Interesting R packages",
    "section": "R packages built from a single *.RMD file",
    "text": "R packages built from a single *.RMD file\nLink"
  },
  {
    "objectID": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#interfaces-to-computer-algebra-systems-in-r",
    "href": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#interfaces-to-computer-algebra-systems-in-r",
    "title": "Interesting R packages",
    "section": "Interfaces to computer algebra systems in R",
    "text": "Interfaces to computer algebra systems in R\nHerre, I have collected a few resources in the field of computer algebra systems that have an interface to R.\n\nGeneral\n\nCRAN task view: Section “Multi-Precision Arithmetic and Symbolic Mathematics” on this site\nBlog article\n\n\n\nMaxima\n\nRim package\n\nextended search path according to these instructions\nposted issue on rim package github site because it is still not working here\nedited /etc/launch.d\nadded shell script /usr/bin/maxima\n\n\n\n\nMaxima successfully registered as knitr engine!\n\n\n[1] TRUE\n\n\n(%o1) 2\n\n\n\n(%i1) lambda_S: beta * psi;\n\n(%o1) beta*psi\n\n(%i2) Lambda_S: integrate(lambda_S, t);\n\n(%o2) beta*psi*t\n\n(%i3) S_S: exp(-Lambda_S);\n\n(%o3) %e^-(beta*psi*t)\n\n(%i4) assume(beta &gt; 0);\n\n(%o4) [beta &gt; 0]\n\n(%i5) assume(psi &gt; 0);\n\n(%o5) [psi &gt; 0]\n\n(%i6) E_S: integrate(S_S, t, 0, inf);\n\n(%o6) 1/(beta*psi)\n\n(%i7) tex(''E_S);\n\n(%o7) false\n\n\n\n\nRyacas\n\n\n\nAttaching package: 'Ryacas'\n\n\nThe following object is masked from 'package:stats':\n\n    integrate\n\n\nThe following objects are masked from 'package:base':\n\n    %*%, det, diag, diag&lt;-, lower.tri, upper.tri\n\n\n[1] 0\n\n\n[1] \"2*x^3-17*x^2+54*x-54\"\n\n\n[1] \"x ^{2} - 1\""
  },
  {
    "objectID": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#flowcharts",
    "href": "posts/2023-03-17-interesting-r-packages/2023-03-17-interesting-r-packages.html#flowcharts",
    "title": "Interesting R packages",
    "section": "Flowcharts",
    "text": "Flowcharts\nSource: https://cran.r-project.org/web/packages/Gmisc/vignettes/Grid-based_flowcharts.html"
  },
  {
    "objectID": "posts/2023-07-12-easier-publishing/2023-07-12-easier-publishing.html",
    "href": "posts/2023-07-12-easier-publishing/2023-07-12-easier-publishing.html",
    "title": "Easier publishing",
    "section": "",
    "text": "In file “publish.sh\n#!   /bin/bash -e\nquarto render\ngit add .\ngit commit -m \"some changes\"\ngit push"
  },
  {
    "objectID": "posts/2023-02-02-strange-behavior-of-geom_area/2023-02-02-strange-behavior-of-geom_area.html",
    "href": "posts/2023-02-02-strange-behavior-of-geom_area/2023-02-02-strange-behavior-of-geom_area.html",
    "title": "Strange behavior in ggplot2",
    "section": "",
    "text": "I have asked a question related to this issue on stackoverflow and I am providing the plots on this page. Here is the question on stackoverflow:\nLink to stackoverflow"
  },
  {
    "objectID": "posts/2023-02-02-strange-behavior-of-geom_area/2023-02-02-strange-behavior-of-geom_area.html#background",
    "href": "posts/2023-02-02-strange-behavior-of-geom_area/2023-02-02-strange-behavior-of-geom_area.html#background",
    "title": "Strange behavior in ggplot2",
    "section": "",
    "text": "I have asked a question related to this issue on stackoverflow and I am providing the plots on this page. Here is the question on stackoverflow:\nLink to stackoverflow"
  },
  {
    "objectID": "posts/2023-02-02-strange-behavior-of-geom_area/2023-02-02-strange-behavior-of-geom_area.html#illustration-of-the-problem",
    "href": "posts/2023-02-02-strange-behavior-of-geom_area/2023-02-02-strange-behavior-of-geom_area.html#illustration-of-the-problem",
    "title": "Strange behavior in ggplot2",
    "section": "Illustration of the problem",
    "text": "Illustration of the problem\n\nlibrary('tidyr')\nlibrary('tibble')\nlibrary('ggplot2')\nlibrary('dplyr')\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ngrid_values &lt;- 2^(-3:3)\n\nstrange_values &lt;- c(-1.90819287770871e-06, -1.68820727726686e-20, 1.90820561104585e-06, \n                    -2.03934646947346e-11, -2.66724989539021e-44, 1.82186185543446e-11, \n                    -3.08642000845794e-14, -2.84079624478981e-68, 3.8017746773927e-20, \n                    -1.55431223447522e-14, -2.12106623568441e-87, -7.04031177308046e-34, \n                    1.99840144432528e-15, 6.92960775272386e-94, -2.17911262386235e-50, \n                    6.43929354282591e-15, 1.60655203590779e-101, -2.4149683145618e-74, \n                    4.2188474935756e-15, -1.63364987668272e-101, -8.43744249369279e-100, \n                    -1.9234795292089e-06, -1.40915667489693e-20, 1.92348291032148e-06, \n                    -7.86031240096463e-11, 5.94869638827445e-40, 1.70218514362265e-11, \n                    -6.21724893790088e-15, -5.32110095875999e-63, 3.9895815730536e-20, \n                    2.39808173319034e-14, -9.91626723546227e-86, -2.47375723122866e-33, \n                    -1.77635683940025e-15, 8.7576689576463e-93, -2.1712899716615e-50, \n                    9.54791801177635e-15, 2.7961387551394e-101, -2.62250706570328e-74, \n                    -6.43929354282591e-15, -5.36337882495689e-101, -1.65540646490924e-99, \n                    -1.95935441282824e-06, -4.13414429145914e-22, 1.9595249500527e-06, \n                    -1.99651406518342e-11, 4.01993294485079e-37, 1.71444629227149e-11, \n                    2.31215047108435e-12, -5.46064224913782e-66, 6.44847728373308e-20, \n                    5.40456568387526e-13, 5.30352631285166e-83, 3.81832474229875e-33, \n                    -1.80966353013901e-14, -9.72418279929888e-94, -2.08007912888974e-51, \n                    -1.33226762955019e-14, 3.23934484578975e-100, -2.61033780134937e-74, \n                    6.88338275267597e-15, -1.29762567303952e-99, -2.07383582042798e-98, \n                    -2.01803061317118e-06, 3.3691909504469e-20, 2.01799435665222e-06, \n                    -1.83731918568242e-11, 7.21526941571507e-42, 1.72812031885596e-11, \n                    1.40298883621881e-11, 2.61529894687986e-38, 2.597261897857e-20, \n                    3.95239396766556e-14, -1.83777217239233e-53, 1.74710015191643e-33, \n                    -2.1316282072803e-14, 3.26611237858842e-68, -1.19804995812909e-51, \n                    -1.58761892521397e-14, 6.58410560104933e-90, -2.50682775406401e-74, \n                    2.46469511466785e-14, -1.08556164510476e-96, -8.68448004693709e-96, \n                    -2.14979959756167e-06, 4.65632478870001e-17, 2.14994451996064e-06, \n                    -2.15127915481617e-11, -5.03897310277035e-29, 2.37451670641299e-11, \n                    -7.30294713591206e-11, -6.74709311307118e-38, 4.03149402823541e-20, \n                    8.21565038222616e-14, 4.6575341905728e-50, -1.71156811032874e-33, \n                    -1.32116539930394e-14, 9.41355218246985e-67, -5.35957793195957e-51, \n                    7.99360577730113e-15, 8.43929875779189e-89, -2.9418326640071e-74, \n                    1.48769885299771e-14, -2.81028796325013e-90, -1.12411483527064e-89, \n                    -2.42728809329851e-06, -8.05503632048299e-18, 2.42718074969143e-06, \n                    5.7643223527748e-11, -5.67417009881705e-30, 2.18227445666839e-11, \n                    4.88498130835069e-15, 5.74369923731793e-37, 5.93253926283155e-20, \n                    -5.36681810103801e-13, 7.68115012003888e-48, 2.12048592220925e-31, \n                    1.43107747874183e-12, -5.9458568180203e-64, 3.32402936140172e-48, \n                    -8.88178419700125e-16, -1.75086766216852e-75, -3.32876019974183e-73, \n                    6.43929354282591e-15, -1.00992378651113e-74, -2.01984753722959e-74, \n                    -2.90572647954068e-06, -7.77642264438329e-10, 2.90649964611508e-06, \n                    9.09130548620851e-11, -3.52178085798882e-12, -8.73905452509179e-11, \n                    -1.03369389016228e-05, 6.07960561736676e-07, 9.72897833978829e-06, \n                    -0.00081769791399311, 9.032308610189e-05, 0.000727374827890998, \n                    -0.0011992740379827, 0.000238928931343064, 0.000960345106639307, \n                    -0.00123663646030969, 0.000411530217922524, 0.000825106242386583, \n                    -0.00124466009860591, 0.000621942028670438, 0.000622718069935415\n)\nmy_tib &lt;- expand_grid(beta = grid_values, lambda = grid_values, name = c('S', 'I', 'R'))\nmy_tib$value &lt;- 0\nmy_tib$value[my_tib$name == 'I'] &lt;- 1\nmy_tib$value_strange &lt;- my_tib$value + strange_values\n\n\n# expected behavior:\nmy_tib %&gt;%\n  ggplot(aes(x = beta, y = value, fill = name)) + geom_area() + facet_grid(cols = vars(lambda)) + scale_x_continuous(trans = 'log10')\n\n\n\n# strange behavior when adding these really small, strange (?) numbers:\nmy_tib %&gt;%\n  ggplot(aes(x = beta, y = value_strange, fill = name)) + geom_area() + facet_grid(cols = vars(lambda)) + scale_x_continuous(trans = 'log10')\n\n\n\n# expected behavior when x axis is not on log-scale\nmy_tib %&gt;%\n  ggplot(aes(x = beta, y = value_strange, fill = name)) + geom_area() + facet_grid(cols = vars(lambda))\n\n\n\n# expected behavior when only the 1's are plotted and the 0's are omitted\nmy_tib %&gt;% filter(name == 'I') %&gt;%\n  ggplot(aes(x = beta, y = value_strange, fill = name)) + geom_area() + facet_grid(cols = vars(lambda)) + scale_x_continuous(trans = 'log10')\n\n\n\n# can't reproduce strange behavior with random numbers - what makes the other numbers so strange that `geom_area` produces weird results?\nset.seed(1)\nmy_tib$value_strange_2 &lt;- my_tib$value + runif(nrow(my_tib), -1e-10, 1e-10)\nmy_tib %&gt;%\n  ggplot(aes(x = beta, y = value_strange_2, fill = name)) + geom_area() + facet_grid(cols = vars(lambda)) + scale_x_continuous(trans = 'log10')\n\n\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Monterey 12.6.2\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] dplyr_1.1.2   ggplot2_3.4.2 tibble_3.2.1  tidyr_1.3.0  \n\nloaded via a namespace (and not attached):\n [1] vctrs_0.6.2       cli_3.6.1         knitr_1.43        rlang_1.1.1      \n [5] xfun_0.39         purrr_1.0.1       generics_0.1.3    jsonlite_1.8.5   \n [9] labeling_0.4.2    glue_1.6.2        colorspace_2.1-0  htmltools_0.5.5  \n[13] scales_1.2.1      fansi_1.0.4       rmarkdown_2.22    grid_4.3.0       \n[17] munsell_0.5.0     evaluate_0.21     fastmap_1.1.1     yaml_2.3.7       \n[21] lifecycle_1.0.3   compiler_4.3.0    htmlwidgets_1.6.2 pkgconfig_2.0.3  \n[25] rstudioapi_0.14   farver_2.1.1      digest_0.6.31     R6_2.5.1         \n[29] tidyselect_1.2.0  utf8_1.2.3        pillar_1.9.0      magrittr_2.0.3   \n[33] withr_2.5.0       gtable_0.3.3      tools_4.3.0"
  },
  {
    "objectID": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html",
    "href": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html",
    "title": "Python study notes",
    "section": "",
    "text": "This section contains my study notes on the official python tutorial.\nHere is a link to the PEP 8 style guide.\nAlso it might be worthwile to look at the official language definition.\n\n\n\nthe_world_is_flat = True\nif the_world_is_flat:\n  print(\"Be careful not to fall off!\")\n\nBe careful not to fall off!\n\n\n\n\n\nSource\n\nspam = 1 \ntext = \"# This is not a comment because it's inside quotes.\"\nsquares = [1, 4, 9, 16, 25]\nsquares[0]\n\n1\n\nsquares[-1]\n\n25\n\nsquares[-3:]\n\n[9, 16, 25]\n\nsquares[:]\n\n[1, 4, 9, 16, 25]\n\nsquares + [36, 49, 64, 81, 100]\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\ncubes = [1, 8, 27, 65, 125]  # something's wrong here\n4 ** 3  # the cube of 4 is 64, not 65!\n\n64\n\ncubes[3] = 64  # replace the wrong value\ncubes\n\n[1, 8, 27, 64, 125]\n\ncubes.append(216)  # add the cube of 6\ncubes.append(7 ** 3)  # and the cube of 7\ncubes\n\n[1, 8, 27, 64, 125, 216, 343]\n\n\n\n# Fibonacci series:\n# the sum of two elements defines the next\na, b = 0, 1\nwhile a &lt; 10:\n    print(a)\n    a, b = b, a+b\n\n0\n1\n1\n2\n3\n5\n8\n\n\n\n\n\n4 builtin data structures: * Lists - x = [1, 2, 3] * Tuples - x = 1, 2, 3 * Sets - x = {1, 2, 3} * Dictionaries x = {'a': 1, 'b': 2, 'c': 3}\n\n\n\nfruits = ['apple', 'banana', 'orange']\nfruits.reverse()\nfruits\n\n['orange', 'banana', 'apple']\n\nfruits[1:]\n\n['banana', 'apple']\n\nfruits[:1]\n\n['orange']\n\nfruits.append('kiwi')\nfruits\n\n['orange', 'banana', 'apple', 'kiwi']\n\n\n\n\n\n\n“immutable lists”\n\n\na = 1, 2, 3, (2, 3, 4), 'a', ('Hello', 'This')\na[3]\n\n(2, 3, 4)\n\n1 &lt; 3 &gt; 1 &lt; 27\n\nTrue\n\n\n\n\n\n\nx = {1, 2, 3}\nx\n\n{1, 2, 3}\n\ny = {'a', 1, 3}\ny\n\n{1, 3, 'a'}\n\nx & y\n\n{1, 3}\n\nx | y\n\n{1, 2, 3, 'a'}\n\nx.add(4)\nx\n\n{1, 2, 3, 4}\n\nx.update([7, 0])\nx\n\n{0, 1, 2, 3, 4, 7}\n\n\n\n\n\n\ntel = {'jack': 4098, 'sape': 4139}\ntel['jan-eggerik'] = 4898\ntel['jan-eggerik'] = 'a'\n'jack' in tel\n\nTrue\n\n'seb' in tel\n\nFalse\n\ndel tel['sape']\nlist(tel)\n\n['jack', 'jan-eggerik']\n\nlist(tel) &lt;= ['jack', 'jan-eggerik']\n\nTrue\n\ndict([('a', 1), ('b', 2)])\n\n{'a': 1, 'b': 2}\n\nx = dict([(1, 'a'), (2, 'b')])\nx[2]\n\n'b'\n\nx['a'] = 3\nx\n\n{1: 'a', 2: 'b', 'a': 3}\n\n# sorted(x) - this will throw an error because of mixing of str and int\nsorted(tel)\n\n['jack', 'jan-eggerik']\n\n\n\nx = 'string'\nbool(x)\n\nTrue\n\nx = ''\nbool(x)\n\nFalse"
  },
  {
    "objectID": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#official-python-tutorial",
    "href": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#official-python-tutorial",
    "title": "Python study notes",
    "section": "",
    "text": "This section contains my study notes on the official python tutorial.\nHere is a link to the PEP 8 style guide.\nAlso it might be worthwile to look at the official language definition.\n\n\n\nthe_world_is_flat = True\nif the_world_is_flat:\n  print(\"Be careful not to fall off!\")\n\nBe careful not to fall off!\n\n\n\n\n\nSource\n\nspam = 1 \ntext = \"# This is not a comment because it's inside quotes.\"\nsquares = [1, 4, 9, 16, 25]\nsquares[0]\n\n1\n\nsquares[-1]\n\n25\n\nsquares[-3:]\n\n[9, 16, 25]\n\nsquares[:]\n\n[1, 4, 9, 16, 25]\n\nsquares + [36, 49, 64, 81, 100]\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\ncubes = [1, 8, 27, 65, 125]  # something's wrong here\n4 ** 3  # the cube of 4 is 64, not 65!\n\n64\n\ncubes[3] = 64  # replace the wrong value\ncubes\n\n[1, 8, 27, 64, 125]\n\ncubes.append(216)  # add the cube of 6\ncubes.append(7 ** 3)  # and the cube of 7\ncubes\n\n[1, 8, 27, 64, 125, 216, 343]\n\n\n\n# Fibonacci series:\n# the sum of two elements defines the next\na, b = 0, 1\nwhile a &lt; 10:\n    print(a)\n    a, b = b, a+b\n\n0\n1\n1\n2\n3\n5\n8\n\n\n\n\n\n4 builtin data structures: * Lists - x = [1, 2, 3] * Tuples - x = 1, 2, 3 * Sets - x = {1, 2, 3} * Dictionaries x = {'a': 1, 'b': 2, 'c': 3}\n\n\n\nfruits = ['apple', 'banana', 'orange']\nfruits.reverse()\nfruits\n\n['orange', 'banana', 'apple']\n\nfruits[1:]\n\n['banana', 'apple']\n\nfruits[:1]\n\n['orange']\n\nfruits.append('kiwi')\nfruits\n\n['orange', 'banana', 'apple', 'kiwi']\n\n\n\n\n\n\n“immutable lists”\n\n\na = 1, 2, 3, (2, 3, 4), 'a', ('Hello', 'This')\na[3]\n\n(2, 3, 4)\n\n1 &lt; 3 &gt; 1 &lt; 27\n\nTrue\n\n\n\n\n\n\nx = {1, 2, 3}\nx\n\n{1, 2, 3}\n\ny = {'a', 1, 3}\ny\n\n{1, 3, 'a'}\n\nx & y\n\n{1, 3}\n\nx | y\n\n{1, 2, 3, 'a'}\n\nx.add(4)\nx\n\n{1, 2, 3, 4}\n\nx.update([7, 0])\nx\n\n{0, 1, 2, 3, 4, 7}\n\n\n\n\n\n\ntel = {'jack': 4098, 'sape': 4139}\ntel['jan-eggerik'] = 4898\ntel['jan-eggerik'] = 'a'\n'jack' in tel\n\nTrue\n\n'seb' in tel\n\nFalse\n\ndel tel['sape']\nlist(tel)\n\n['jack', 'jan-eggerik']\n\nlist(tel) &lt;= ['jack', 'jan-eggerik']\n\nTrue\n\ndict([('a', 1), ('b', 2)])\n\n{'a': 1, 'b': 2}\n\nx = dict([(1, 'a'), (2, 'b')])\nx[2]\n\n'b'\n\nx['a'] = 3\nx\n\n{1: 'a', 2: 'b', 'a': 3}\n\n# sorted(x) - this will throw an error because of mixing of str and int\nsorted(tel)\n\n['jack', 'jan-eggerik']\n\n\n\nx = 'string'\nbool(x)\n\nTrue\n\nx = ''\nbool(x)\n\nFalse"
  },
  {
    "objectID": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#seaborn",
    "href": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#seaborn",
    "title": "Python study notes",
    "section": "Seaborn",
    "text": "Seaborn\n\nGallery\n\n\nimport seaborn as sns\nimport matplotlib as mp\nimport matplotlib.pyplot as plt\n\n# Apply the default theme\nsns.set_theme()\n\n# Load an example dataset\n\n\ndots = sns.load_dataset(\"dots\")\n\nsns.set(rc={'figure.figsize':(10, 3)})\n\nsns.relplot(\n  data=dots, kind=\"line\",\n  x=\"time\", y=\"firing_rate\", col=\"align\", # style = \"choice\",\n  hue=\"choice\", size=\"coherence\", \n  facet_kws=dict(sharex=False)\n  )\n\n\n\n#mp.pyplot.show()\n\n\n# sns.set_theme(style=\"whitegrid\")\n\nx = (5,5)\n\nsns.set(rc={'figure.figsize': x})\n\n\n# Load the example diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Draw a scatter plot while assigning point colors and sizes to different\n# variables in the dataset\nf, ax = plt.subplots(figsize=x)\nsns.despine(f, left=True, bottom=True)\nclarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(x=\"carat\", y=\"price\",\n                hue=\"clarity\", size=\"depth\",\n                palette=\"ch:r=-.2,d=.3_r\",\n                hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=diamonds, ax=ax)"
  },
  {
    "objectID": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#python-libraries-i-want-to-look-at",
    "href": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#python-libraries-i-want-to-look-at",
    "title": "Python study notes",
    "section": "Python libraries I want to look at",
    "text": "Python libraries I want to look at\n\nNumpy - Documentation\nMatplotlib - Tutorials\nSeaborn - Tutorials\nSciPy - User Guide -\nSciKit-Learn - Tutorials\nstatsmodels - Getting started\npandas - Tutorials\npytorch and co\nDjango - Tutorial using VS Code\nPlotly"
  },
  {
    "objectID": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#python-and-quarto-issues",
    "href": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#python-and-quarto-issues",
    "title": "Python study notes",
    "section": "Python and quarto issues",
    "text": "Python and quarto issues\n\nFigure size seems to be not adjustable by chunk options if engine is jupyter\n\n–&gt; use knitr as engine\nHere fig-size seems to work at least with matplotlib, other packages not tested\n\nWith knitr as engine, I think by default the following python executable is\n\n\nsystem('which python', intern = TRUE)\n\n[1] \"/Users/seb/Library/r-miniconda-arm64/envs/sbloggel/bin/python\"\n\n\n\nimport sys\nprint(sys.executable)\n\n/Users/seb/Library/r-miniconda-arm64/envs/sbloggel/bin/python\n\n\n\nIn the default environment, I was able to install packages with the following command:\n\n\nlibrary('reticulate')\n# conda_install('r-reticulate', 'matplotlib')\n \n\n# This did not work:\n# py_install(\"pandas\")"
  },
  {
    "objectID": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#pandas",
    "href": "posts/2023-03-17-python-study-notes/2023-03-17-python-study-notes.html#pandas",
    "title": "Python study notes",
    "section": "Pandas",
    "text": "Pandas\n\nTutorials"
  },
  {
    "objectID": "posts/2022-09-08-antipsychotics/2022-09-08-antipsychotics.html",
    "href": "posts/2022-09-08-antipsychotics/2022-09-08-antipsychotics.html",
    "title": "Antipsychotics",
    "section": "",
    "text": "Dopamin-Rezeptoren\n\nD_1/D_5-Gruppe: Signalübertragung durch stimulatorisches G-Protein –&gt; cAMP hoch\nD_2/D_3/D_4-Gruppe: Signalübertragung durch hemmendes G-Protein –&gt; cAMP runter\n\n\n\nWichtige dopaminerge Neuronensysteme\n\nNigrostriatales System: Motorik (damit auch EPS)\nMesolimbisches / mesokortikales System: Hauptangriffsort der Antipsychotika\nTuberoinfundibuläres System: vermittelt die neuroendokrinologischen NW, insbesondere Prolaktin-Anstieg\n\n\n\nAntipsychotika\n\n\nWarning in read.ods(\"Antipsychotics.ods\", sheet = 1): read.ods will be\ndeprecated in the next version. Use read_ods instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubstanz\nKlasse\nTrizyklisch\nTyp\nPotenz\nD1\nD2\nD3\nSer2\nM1\nalpha1\nH1\n\n\n\n\nAmisulprid\nBenzamid\n0\nAAP\nNA\n0\n3\n3\n0\n0\n0\n0\n\n\nAripiprazol\nPhenylpiperazinylcholin\n0\nAAP\nNA\n0\n3\n3\n2\n0\n1\n1\n\n\nAsenapin\nDibenzooxepinpyrrol\n0\nAAP\nNA\n1\n1\n2\n2\n0\n1\n1\n\n\nBenperidol\nButyrophenon\n0\nKAP\nHP\n0\n3\n2\n2\n0\n1\n0\n\n\nBromperidol\nButyrophenon\n0\nKAP\nHP\n1\n3\n2\n0\n0\n1\n0\n\n\nChorprothixen\nThioxanthen\n1\nKAP\nNP\n2\n1\n1\n2\n1\n1\n3\n\n\nClozapin\nDibenzodiazepin\n1\nAAP\nNA\n2\n1\n2\n3\n3\n1\n3\n\n\nFlupentixol\nThioxeanthen\n1\nKAP\nHP\n2\n3\n3\n2\n0\n1\n1\n\n\nFluphenazin\nPhenothiazin\n1\nKAP\nHP\n2\n3\n3\n2\n0\n2\n2\n\n\nFluspirilen\nDiphenylbutylpiperidin\n0\nKAP\nHP\n1\n3\n2\n1\n0\n0\n0\n\n\nHaloperidol\nButyrophenon\n0\nKAP\nHP\n2\n3\n2\n1\n0\n2\n0\n\n\nLevomepromazin\nPhenothiazin\n1\nKAP\nNP\n0\n1\n1\n1\n2\n2\n2\n\n\nLoxapin\nDibenzoxazepin\n1\nKAP\nMP\n0\n3\n1\n3\n2\n3\n3\n\n\nLurasidon\nBenzoisothiazol\n0\nAAP\nNA\n1\n3\n2\n3\n0\n2\n0\n\n\nMelperon\nButyrophenon\n0\nKAPA\nNP\n0\n1\n1\n2\n0\n1\n1\n\n\nOlanzapin\nThienobenzazepin\n1\nAAP\nNA\n2\n3\n2\n3\n2\n2\n3\n\n\nPaliperidon\nBenzisoxazol\n0\nAAP\nNA\n0\n3\n1\n3\n0\n1\n1\n\n\nPerazin\nPhenothiazin\n1\nKAP\nMP\n0\n2\n2\n2\n1\n2\n3\n\n\nPerphenazin\nPhenothiazin\n1\nKAP\nHP\n0\n3\n3\n2\n0\n2\n2\n\n\nPimozid\nDiphenylbutylpiperidin\n0\nKAP\nHP\n0\n3\n3\n2\n0\n0\n0\n\n\nPipameron\nButyrophenon\n0\nKAP\nNP\n0\n1\n1\n2\n0\n1\n0\n\n\nProthipendyl\nPhenothiazin\n1\nKAP\nNP\nNA\n1\nNA\nNA\nNA\nNA\nNA\n\n\nQuetiapin\nDibenzothiazepin\n1\nAAP\nNA\n1\n1\n1\n1\n0\n1\n2\n\n\nRisperidon\nBenzisoxazol\n0\nAAP\nNA\n2\n3\n2\n3\n0\n3\n1\n\n\nSertindol\nIndol\n0\nAAP\nNA\n2\n3\n1\n3\n0\n2\n0\n\n\nSulpirid\nBenzamid\n0\nKAPA\nMP\n0\n1\n3\n0\n0\n0\n0\n\n\nThioridazin\nPhenothiazin\n1\nKAP\nNP\n1\n2\n1\n2\n3\n3\n1\n\n\nZiprasidon\nBenzisothiazin\n0\nAAP\nNA\n1\n2\n2\n3\n0\n1\n2\n\n\nZuclopenthixol\nThioxanthen\n1\nKAP\nMP\n2\n3\n2\n0\n3\n3\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubstanz\nKlasse\nTrizyklisch\nTyp\nPotenz\nD1\nD2\nD3\nSer2\nM1\nalpha1\nH1\n\n\n\n\n\nAmisulprid : 1\nPhenothiazin : 6\nMin. :0.0000\nAAP :11\nHP : 8\nMin. :0.0000\nMin. :1.000\nMin. :1.000\nMin. :0.000\nMin. :0.0000\nMin. :0.000\nMin. :0.00\n\n\n\nAripiprazol : 1\nButyrophenon : 5\n1st Qu.:0.0000\nKAP :16\nMP : 4\n1st Qu.:0.0000\n1st Qu.:1.000\n1st Qu.:1.000\n1st Qu.:1.000\n1st Qu.:0.0000\n1st Qu.:1.000\n1st Qu.:0.00\n\n\n\nAsenapin : 1\nBenzamid : 2\nMedian :0.0000\nKAPA: 2\nNP : 6\nMedian :1.0000\nMedian :3.000\nMedian :2.000\nMedian :2.000\nMedian :0.0000\nMedian :1.000\nMedian :1.00\n\n\n\nBenperidol : 1\nBenzisoxazol : 2\nMean :0.4483\nNA\nNA’s:11\nMean :0.8929\nMean :2.276\nMean :1.929\nMean :1.857\nMean :0.6071\nMean :1.429\nMean :1.25\n\n\n\nBromperidol : 1\nDiphenylbutylpiperidin: 2\n3rd Qu.:1.0000\nNA\nNA\n3rd Qu.:2.0000\n3rd Qu.:3.000\n3rd Qu.:2.250\n3rd Qu.:3.000\n3rd Qu.:1.0000\n3rd Qu.:2.000\n3rd Qu.:2.00\n\n\n\nChorprothixen: 1\nThioxanthen : 2\nMax. :1.0000\nNA\nNA\nMax. :2.0000\nMax. :3.000\nMax. :3.000\nMax. :3.000\nMax. :3.0000\nMax. :3.000\nMax. :3.00\n\n\n\n(Other) :23\n(Other) :10\nNA\nNA\nNA\nNA’s :1\nNA\nNA’s :1\nNA’s :1\nNA’s :1\nNA’s :1\nNA’s :1"
  },
  {
    "objectID": "posts/2023-07-05-python-graphics/2023-07-05-python-graphics.html",
    "href": "posts/2023-07-05-python-graphics/2023-07-05-python-graphics.html",
    "title": "Python graphics",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.get_dataset_names()\n\n['anagrams', 'anscombe', 'attention', 'brain_networks', 'car_crashes', 'diamonds', 'dots', 'dowjones', 'exercise', 'flights', 'fmri', 'geyser', 'glue', 'healthexp', 'iris', 'mpg', 'penguins', 'planets', 'seaice', 'taxis', 'tips', 'titanic']\n\niris = sns.load_dataset('iris')"
  },
  {
    "objectID": "posts/2023-07-05-python-graphics/2023-07-05-python-graphics.html#matplotlib",
    "href": "posts/2023-07-05-python-graphics/2023-07-05-python-graphics.html#matplotlib",
    "title": "Python graphics",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nplt.rcParams['figure.figsize'] = [12, 5]\nfig, ax = plt.subplots()\nax.set_xlabel('Sepal length')\nax.set_ylabel('Sepal width')\nax.set_title('Iris dataset')\nax.scatter(iris['sepal_length'], iris['sepal_width'])\nplt.show()"
  },
  {
    "objectID": "posts/2023-07-05-python-graphics/2023-07-05-python-graphics.html#seaborn",
    "href": "posts/2023-07-05-python-graphics/2023-07-05-python-graphics.html#seaborn",
    "title": "Python graphics",
    "section": "Seaborn",
    "text": "Seaborn\n\ng = sns.FacetGrid(iris, col = 'species', col_wrap = 1, height = 2, aspect = 2)\ng = g.map(plt.scatter, 'sepal_length', 'sepal_width')\nplt.show()\n\n\n\n\n\n\n\nplt.close()"
  },
  {
    "objectID": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html",
    "href": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html",
    "title": "SIRS model dynamics",
    "section": "",
    "text": "library('ggplot2')\nlibrary('tidyverse')\nlibrary('deSolve')\ntheme_set(theme_bw())"
  },
  {
    "objectID": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html#loading-the-required-libraries",
    "href": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html#loading-the-required-libraries",
    "title": "SIRS model dynamics",
    "section": "",
    "text": "library('ggplot2')\nlibrary('tidyverse')\nlibrary('deSolve')\ntheme_set(theme_bw())"
  },
  {
    "objectID": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html#simulate-odes",
    "href": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html#simulate-odes",
    "title": "SIRS model dynamics",
    "section": "Simulate ODEs",
    "text": "Simulate ODEs\n\nsir_ode_deterministic &lt;- function(t, state, pars) {\n  with(as.list(c(state, pars)), {\n    dS &lt;- - beta * I * S + lambda * R\n    dI &lt;- beta * I * S - gamma * I\n    dR &lt;- gamma * I - lambda * R\n    return(list(c(dS = dS, dI = dI, dR = dR)))\n  }) \n}\n\n\ninfected_initial &lt;- 0.5\ninitial_condition &lt;- \n  c(S = 1 - infected_initial,\n    I = infected_initial,\n    R = 0)\n\nstep_length &lt;- 1\nmax_time &lt;- 100\ntimepoints &lt;- seq(0, max_time, by = step_length)\ngrid_values &lt;- 2^(-1:1)\ngrid_values &lt;- 2^(-2:2)\ngrid_values &lt;- 2^(-3:3)\n\nresult &lt;- tibble()\nfor(beta in grid_values) {\n  for(gamma in grid_values) {\n    for(lambda in grid_values) {\n      parameters &lt;- list(beta = beta, \n                         gamma = gamma,\n                         lambda = lambda)\n      solution &lt;- ode(y = initial_condition, \n                      times = timepoints,\n                      func = sir_ode_deterministic,\n                      parms = parameters) %&gt;% \n        unclass %&gt;% as_tibble\n      solution$beta &lt;- beta\n      solution$gamma &lt;- gamma\n      solution$lambda &lt;- lambda\n      result &lt;- rbind(result, solution)\n    }\n  }\n}\n\nresult &lt;- pivot_longer(result, cols = c('S', 'I', 'R'))\n\nlast &lt;- result %&gt;% \n  filter(time == max_time) %&gt;% \n  mutate(name = factor(name, levels = c('S', 'I', 'R')))\n\nlast %&gt;%\n  ggplot(aes(beta, value, colour = name)) + \n  geom_point() + geom_line() +\n  facet_grid(rows = vars(gamma), \n             cols = vars(lambda), \n             labeller = label_both) +\n  labs(xlab = 'beta', ylab = 'Fraction', colour = 'Compartment') +\n  scale_x_continuous(trans='log10')\n\n\n\nlast %&gt;%\n  ggplot(aes(x = beta, y = value, fill = name)) +\n  geom_area() +\n  facet_grid(rows = vars(gamma), \n             cols = vars(lambda), \n             labeller = label_both) +\n  labs(xlab = 'beta', ylab = 'Fraction', fill = 'Compartment') +\n  scale_x_continuous(trans='log10')\n\n\n\nss &lt;- last %&gt;% \n  group_by(beta, gamma, lambda) %&gt;% \n  summarise(ss = sum(value))\n\n`summarise()` has grouped output by 'beta', 'gamma'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html#analytical-approach",
    "href": "posts/2023-01-20-sirs-model-dynamics/2023-01-20-sirs-model-dynamics.html#analytical-approach",
    "title": "SIRS model dynamics",
    "section": "Analytical approach",
    "text": "Analytical approach\nSolution in terms of parameters in red.\n\nEquilibrium conditions\n\\[\n\\begin{align}\n1 &= S + I + R  \\qquad &(1) \\\\\n0 &= -\\beta I S + \\lambda R \\qquad &(2) \\\\\n0 &= \\beta I S - \\gamma I \\qquad &(3) \\\\\n0 &= \\gamma I - \\lambda R \\qquad &(4)\n\\end{align}\n\\]\n\n\nAlgebraic transformation\n\\[\n\\begin{align}\nR &= 1 - S - I \\qquad &(1b) \\\\\nS &= \\gamma / \\beta \\qquad &(3b)\n\\end{align}\n\\]\n\n\nPlugging in\n\\[\n\\begin{align}\n(3b) \\rightarrow (2): \\quad I &= \\lambda / \\gamma R  \\qquad &(5) \\\\\n(1b) \\rightarrow (5): \\quad I &= \\frac{\\lambda(\\beta - \\gamma)}{\\beta(\\gamma + \\lambda)} \\qquad &(6) \\\\\n(3b) + (6) \\rightarrow (1b): R &= \\frac{\\gamma(\\beta - \\gamma)}{\\beta(\\gamma + \\lambda)} \\qquad &(7)\n\\end{align}\n\\]\n\n\nPlots\n\nlast_w &lt;- pivot_wider(last, names_from = name, values_from = value)\nlast_w$S_calc &lt;- pmin(1, last_w$gamma / last_w$beta)\nlast_w$I_calc &lt;- \n  pmax(0, pmin(1, with(last_w, (lambda * (beta - gamma))) / \n                 (beta * (gamma + lambda))))\nlast_w$R_calc &lt;- \n  pmax(0, pmin(1, with(last_w, (gamma * (beta - gamma)) / \n                         (beta * (gamma + lambda)))))\n\nlast_w$I_calc &lt;- 1 - last_w$S_calc - last_w$R_calc\n\nlast &lt;- last_w %&gt;% \n  pivot_longer(cols = c('S_calc', 'I_calc', 'R_calc'))\n\n\nlast %&gt;%\n  ggplot(aes(x = beta, y = value, fill = name)) + \n  geom_area() +\n  facet_grid(rows = vars(gamma), \n             cols = vars(lambda), \n             labeller = label_both) +\n  labs(ylab = 'Fraction',  xlab = 'beta', colour = 'Compartment') +\n  scale_x_continuous(trans='log10')"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html",
    "title": "Leo’s project",
    "section": "",
    "text": "In hematological cancers, blood stem cells can be transferred to a patient after chemothery. The blood stem cells may proliferate in the patient and populate the patient’s peripheral blood afterwards.\nChimerism is defined as the ratio of the number of blood cells originating from the transplanted cells and the total number of blood cells in the patient’s blood.\nHere, a sigmoidal model for the temporal development of chimerism after transplantion is introduced and in silico data are simulated.\nLeo also posted a question about this model on the STAN forum: https://discourse.mc-stan.org/t/bad-diagnostics-with-multilevel-models/29091?u=leonhardschwager\n\n\n\n\nlibrary('tidyverse')\nset.seed(1)\n\n\n\n\n\nSource: https://en.wikipedia.org/wiki/Logistic_function\n\n\ncalc_chimerism &lt;- function(day, d = 1, b = 1, e = 5) {\n# day: for which day the chimerism shall be calculated\n# d: maximum value of the curve\n# b: the logistic growth rate or steepness of the curve\n# e:  location of the midpoint of the sigmoid function\n  d / (1 + exp(-b * (day - e)))\n}\n\n# plot the function with default values:\nggplot() + stat_function(fun = calc_chimerism) + \n  xlim(0, 10) + labs(x = 'Time', y = 'Chimerism')\n\n\n\n\n\n\n\n\nnr_of_patients &lt;- 10\nnr_of_measurements &lt;- 10 # per patient\nd &lt;- runif(n = nr_of_patients, min = 0.6, max = 1)\nb &lt;- rnorm(n = nr_of_patients, mean = 1, sd = 0.1)\ne &lt;- runif(n = nr_of_patients, min = 5, max = 15)\n\n\n\n\n\ndat &lt;- tibble(patient_id = factor(1:nr_of_patients), \n              d = d, \n              b = b, \n              e = e) %&gt;%\n  expand_grid(measurement = 1:nr_of_measurements)\n\n# compute timepoints symetrical equidistant \n# in both directions of the sigmoid midpoint \n# of the curve:\ndat$day &lt;- dat$e * 2 * dat$measurement / nr_of_measurements\n\n\n\n\n\ndat$chimerism &lt;- calc_chimerism(day = dat$day, \n                                d = dat$d, \n                                b = dat$b, \n                                e = dat$e)\n\n\n\n\n\nggplot(dat, aes(day, chimerism)) + \n  geom_point() + geom_line() + \n  facet_wrap(~ patient_id, ncol = 3, scales = 'free_x') + \n  xlim(0, NA) + ylim(0, 1)\n\n\n\nggplot(dat, aes(day, chimerism, color = patient_id)) + \n  geom_point() + geom_line() + \n  ylim(0, 1)"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#background",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#background",
    "title": "Leo’s project",
    "section": "",
    "text": "In hematological cancers, blood stem cells can be transferred to a patient after chemothery. The blood stem cells may proliferate in the patient and populate the patient’s peripheral blood afterwards.\nChimerism is defined as the ratio of the number of blood cells originating from the transplanted cells and the total number of blood cells in the patient’s blood.\nHere, a sigmoidal model for the temporal development of chimerism after transplantion is introduced and in silico data are simulated.\nLeo also posted a question about this model on the STAN forum: https://discourse.mc-stan.org/t/bad-diagnostics-with-multilevel-models/29091?u=leonhardschwager"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#initialization",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#initialization",
    "title": "Leo’s project",
    "section": "",
    "text": "library('tidyverse')\nset.seed(1)"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#definition-of-model-function-to-predict-chimerism",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#definition-of-model-function-to-predict-chimerism",
    "title": "Leo’s project",
    "section": "",
    "text": "Source: https://en.wikipedia.org/wiki/Logistic_function\n\n\ncalc_chimerism &lt;- function(day, d = 1, b = 1, e = 5) {\n# day: for which day the chimerism shall be calculated\n# d: maximum value of the curve\n# b: the logistic growth rate or steepness of the curve\n# e:  location of the midpoint of the sigmoid function\n  d / (1 + exp(-b * (day - e)))\n}\n\n# plot the function with default values:\nggplot() + stat_function(fun = calc_chimerism) + \n  xlim(0, 10) + labs(x = 'Time', y = 'Chimerism')"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#set-parameters",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#set-parameters",
    "title": "Leo’s project",
    "section": "",
    "text": "nr_of_patients &lt;- 10\nnr_of_measurements &lt;- 10 # per patient\nd &lt;- runif(n = nr_of_patients, min = 0.6, max = 1)\nb &lt;- rnorm(n = nr_of_patients, mean = 1, sd = 0.1)\ne &lt;- runif(n = nr_of_patients, min = 5, max = 15)"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#construct-independent-values",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#construct-independent-values",
    "title": "Leo’s project",
    "section": "",
    "text": "dat &lt;- tibble(patient_id = factor(1:nr_of_patients), \n              d = d, \n              b = b, \n              e = e) %&gt;%\n  expand_grid(measurement = 1:nr_of_measurements)\n\n# compute timepoints symetrical equidistant \n# in both directions of the sigmoid midpoint \n# of the curve:\ndat$day &lt;- dat$e * 2 * dat$measurement / nr_of_measurements"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#apply-model-function-to-calculate-dependendant-values",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#apply-model-function-to-calculate-dependendant-values",
    "title": "Leo’s project",
    "section": "",
    "text": "dat$chimerism &lt;- calc_chimerism(day = dat$day, \n                                d = dat$d, \n                                b = dat$b, \n                                e = dat$e)"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#plot-the-simulated-data",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#plot-the-simulated-data",
    "title": "Leo’s project",
    "section": "",
    "text": "ggplot(dat, aes(day, chimerism)) + \n  geom_point() + geom_line() + \n  facet_wrap(~ patient_id, ncol = 3, scales = 'free_x') + \n  xlim(0, NA) + ylim(0, 1)\n\n\n\nggplot(dat, aes(day, chimerism, color = patient_id)) + \n  geom_point() + geom_line() + \n  ylim(0, 1)"
  },
  {
    "objectID": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#fitting-a-simple-model",
    "href": "posts/2022-10-16-leo-s-project/2022-10-16-leo-s-project.html#fitting-a-simple-model",
    "title": "Leo’s project",
    "section": "Fitting a simple model",
    "text": "Fitting a simple model\n\nlibrary('brms')\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.19.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n# help(package = 'brms')\n# prior1 &lt;- prior(normal(1, 0.1), nlpar = ')"
  },
  {
    "objectID": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html",
    "href": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html",
    "title": "Sustainibility data",
    "section": "",
    "text": "Quelle: Blog\nEnergie pro Jahr:\n\n\n# Wie viele Watt pro qm Erdoberfläche liefert die Sonne im Mittel:\nwatt_per_sqm &lt;- 1340\n# Wie groß ist die Oberfläche der Erde:\nsurface_earth_sqm &lt;- 5.1e14\n# Wie viel Sonnenenergie erreicht die Erde pro Jahr:\nenergy_sun_per_year_joule &lt;- watt_per_sqm * surface_earth_sqm * 60 * 60 * 24 * 365.25\n(energy_per_year_kwh &lt;- energy_sun_per_year_joule / 3.6e6)\n\n[1] 5.990684e+18"
  },
  {
    "objectID": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html#wie-viel-energie-liefert-die-sonne",
    "href": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html#wie-viel-energie-liefert-die-sonne",
    "title": "Sustainibility data",
    "section": "",
    "text": "Quelle: Blog\nEnergie pro Jahr:\n\n\n# Wie viele Watt pro qm Erdoberfläche liefert die Sonne im Mittel:\nwatt_per_sqm &lt;- 1340\n# Wie groß ist die Oberfläche der Erde:\nsurface_earth_sqm &lt;- 5.1e14\n# Wie viel Sonnenenergie erreicht die Erde pro Jahr:\nenergy_sun_per_year_joule &lt;- watt_per_sqm * surface_earth_sqm * 60 * 60 * 24 * 365.25\n(energy_per_year_kwh &lt;- energy_sun_per_year_joule / 3.6e6)\n\n[1] 5.990684e+18"
  },
  {
    "objectID": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html#weltenergiebedarf",
    "href": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html#weltenergiebedarf",
    "title": "Sustainibility data",
    "section": "Weltenergiebedarf",
    "text": "Weltenergiebedarf\n\nWikipedia: Weltenergiebedarf 574 Exajoule = 5.74e20\n\n\n# Weltenergiebedarf:\nworld_energy_consumption_joule &lt;- 5.74e20\n(world_energy_consumption_kwh &lt;- world_energy_consumption_joule / 3.6e6)\n\n[1] 1.594444e+14\n\n# Wie viel mal so viel Energie liefert die Sonne:\nfac &lt;- energy_sun_per_year_joule / world_energy_consumption_joule\n\nDie Welt liefert also ca. 3.76e+04 mal so viel Energie wie von den Menschen verbraucht wird.\n\n# angenommene Effizienz von Photovoltaikanlagen:\nassumed_efficiency &lt;- 0.1\n# Welcher Anteil der Erde müsste mit 'mittleren' PV-Anlagen bedeckt sein, um den Weltenergiebedarf mit PV-Anlagen abdecken zu können:\nfraction_earth &lt;- 1 / (assumed_efficiency * fac)\n# Weltbevölkerung:\npopulation_earth &lt;- 8e9\n# Wie viel \n(pv_per_person &lt;- surface_earth_sqm * fraction_earth / population_earth)\n\n[1] 16.96732"
  },
  {
    "objectID": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html#deutschland",
    "href": "posts/2023-01-10-sustainibility-data/2023-01-10-sustainibility-data.html#deutschland",
    "title": "Sustainibility data",
    "section": "Deutschland",
    "text": "Deutschland\n\nWikipedia: Weltenergiebedarf 574 Exajoule = 5.74e20\n\n\n(energy_consumption_germany_joule &lt;- 3.3 * 1e3 * 1e9 * 3.6e6)\n\n[1] 1.188e+19\n\nsurface_germany_sqm &lt;- 3e5 * 1e6\nenergy_sun_germany_year_joule &lt;- watt_per_sqm * surface_germany_sqm * 60 * 60 * 24 * 365.24\n# Anteil der Fläche in Deutschland, der mit PV-Anlagen ausgestatted sein müsste:\nenergy_consumption_germany_joule / (energy_sun_germany_year_joule * assumed_efficiency)\n\n[1] 0.009364796"
  },
  {
    "objectID": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html",
    "href": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html",
    "title": "Coursera Deep Learning Specialization",
    "section": "",
    "text": "How to input images of different dimensions in a neural net?\nI don’t quite understand yet how convolutions finally integrate more than just local information. In my understanding this can only happen efficiently in the fully connected layers then?\nUnderstand cost function and understand the derivatives\nKeras works with float32 (single float) - double is never used? Single is sufficient?\nRead a little about Boltzmann machines"
  },
  {
    "objectID": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#study-questions",
    "href": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#study-questions",
    "title": "Coursera Deep Learning Specialization",
    "section": "",
    "text": "How to input images of different dimensions in a neural net?\nI don’t quite understand yet how convolutions finally integrate more than just local information. In my understanding this can only happen efficiently in the fully connected layers then?\nUnderstand cost function and understand the derivatives\nKeras works with float32 (single float) - double is never used? Single is sufficient?\nRead a little about Boltzmann machines"
  },
  {
    "objectID": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#course-2-week-2",
    "href": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#course-2-week-2",
    "title": "Coursera Deep Learning Specialization",
    "section": "Course 2, Week 2",
    "text": "Course 2, Week 2\n\nMini-batch Gradient Descent\n\nhow do I controll this in Keras / PyTorch / whatever?\nmini batch size = 1 -&gt; stochastic gradient descent\nmini batch size power of 2\n\n\n\nExponentially moving averages:\n\\[V_t = \\beta V_{t-1} + (1 - \\beta) \\theta_t\\] * this corresponds approximately to averaging over \\(\\frac{1}{1-\\beta}\\) entries\n\n\nGradient descent with momentum\n\ngradients with exponentially moving average\nif learning rate too large risk of diverging\nlocal minima are not the main problem - the problem are saddle points!\nball on a hill: velocity is stored in the average, new gradient is the acceleration\n\\(\\beta = 0.9\\) averaging over approx. the last 10 iterations\nUpdate rule: \\[ V_{dw} = \\beta V_{dw} + (1-\\beta) dW\\]\noften approximated by: \\[ V_{dw} = \\beta V_{dw} + dW\\]\n\n\n\nRoot Mean Square Propagation\n\ndW is small, db is large (is this true?), here we call the hyperparameter \\(\\beta_2\\), also \\(\\epsilon = 10^{-8}\\) \\[ S_{dW} := \\beta S_{dW} + (1 - \\beta) dW^2\\] \\[ W := W - \\alpha \\frac{dW}{\\sqrt{S_{dW}} + \\epsilon}\\] \\[ S_{db} := \\beta S_{db} + (1 - \\beta) db^2\\] \\[ W := W - \\alpha \\frac{db}{\\sqrt{S_{db}} + \\epsilon}\\]\n\n\n\nAdaptive moment estimation optimization algorithm (Adam)\nInitiliazation: \\(V_{dW} = 0\\), \\(S_{dW} = 0\\), \\(V_{db} = 0\\), \\(S_{db} = 0\\), \\[ V_{dW} = \\beta_1 V_{dW} + (1 - \\beta_1) dW\\] \\[ V_{db} = \\beta_1 V_{db} + (1 - \\beta_1) db\\] \\[ S_{dW} = \\beta_2 S_{dW} + (1 - beta_2) dW^2\\] \\[ S_{db} = \\beta_2 S_{db} + (1 - beta_2) db^2\\] Typically implemented with bias correction \\[ V_{dW}^{corrected} = V_{dW} / (1 - \\beta_1 ^ t)\\] \\[ V_{db}^{corrected} = V_{db} / (1 - \\beta_1 ^ t)\\] \\[ S_{dW}^{corrected} = S_{dW} / (1 - \\beta_2 ^ t)\\] \\[ S_{db}^{corrected} = S_{db} / (1 - \\beta_2 ^ t)\\] Update rule: \\(w := w - \\alpha \\frac{V_{dW}^{corrected}}{\\sqrt{S^{corrected}_{dW}} + \\epsilon}\\) \\(b := b - \\alpha \\frac{V_{db}^{corrected}}{\\sqrt{S^{corrected}_{db}} + \\epsilon}\\) Hyperparameters:\n\n\\(\\alpha\\) needs to be tuned\n\\(\\beta_1\\): usually 0.9\n\\(\\beta_2\\): usually 0.999\n$ $:usually \\(10e-8\\)\n\n\n\nLearning rate decay\n\\[ \\alpha = 1 / (1 + {decayrate} \\times {epochnumber})  \\alpha_0\\]\n\n\nSoftmax activation function\n\\[ a_i = \\frac{\\exp{z_i}}{\\sum_{j=1}^{n}{\\exp{z_j}}}\\]\n\n\nSoftmax regression\n\ngeneralization of logistic regression to \\(n\\) classes\nLikelihood: \\[ L(\\hat{y}, y) = - \\sum^C_{j = 1} y_j log \\hat{y_j} \\]"
  },
  {
    "objectID": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#course-3-week-2",
    "href": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#course-3-week-2",
    "title": "Coursera Deep Learning Specialization",
    "section": "Course 3, Week 2",
    "text": "Course 3, Week 2\n\nAvoidable bias: discrepancy between Bayes’ error and training error\n\n\nBias and variance with mismatched data distrubtions\n\npotential help: add a Training-dev set\ntraining error, training-dev error, dev error\ndata mismatch problem\nData augmentation: when sampling only a small subset of all possible examples overfitting may occur (e. g. cars in a video game)\nTransfer learning: example image recognition\n\ntrain network to a lot of images\nnow x-rays: delete weights of the last layer of the network and retrain them (a few x-rays available for training) or all parameters of the network (a lot of x-rays available for training)\n\nMultitask learning - output vector, doesn’t have to be fully labeled\nTransfer learning currently learned more frequently than multitask learning\nMultitask learning: each class should have similar number of items"
  },
  {
    "objectID": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#course-4",
    "href": "posts/2023-03-17-coursera-deep-learning/2023-03-17-coursera-deep-learning.html#course-4",
    "title": "Coursera Deep Learning Specialization",
    "section": "Course 4",
    "text": "Course 4\n\nstrided and padded convolution\ncross-correlation (without flipping) vs. convolution (flipping around vertical and horizontal axis) - in ML, cross-correlation is by convention also called convolution\nconvolutions over volumes (\\(n_c\\) = number of channels) \\[ n \\times n \\times n_c * f \\times f \\times n_c \\rightarrow (n - f + 1) * (n - f + 1) * n_c^{prime}\\]\nprime means in the next layer\n\n\nPooling\n\nmax pooling: only hyperparameters stride, padding (usually zero) and f\naverage pooling: rarely used, very sometimes for example to collapse spatial dimension (e.g. 7x7 with 1000 channels to 1x1 with 1000 channels)\nno parameters to learn"
  },
  {
    "objectID": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html",
    "href": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html",
    "title": "How bad are bananas",
    "section": "",
    "text": "Recently, I have come a across a book that I find really wonderful: “How bad are bananas” by Mike Berners-Lee Berners-Lee (2020).\nI would really like to use some of the data for a school project (of course citing the source in an adequate manner). It would be nice to use the data to develop a simple footprint calculator that is available online. Explicite permission from the author to use the data from his book with appropriate inidication of the data source is pending, however, with proper citation it should be okay to use the data I figure."
  },
  {
    "objectID": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#reading-notes",
    "href": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#reading-notes",
    "title": "How bad are bananas",
    "section": "Reading notes",
    "text": "Reading notes\n\nCarbon dioxide equivalent (CO2e):\n\namount of CO2 that would have the same impact over a time of 100 years\nTotal impact in the UK\n\ncarbon dioxide 81%\nmethane 11%\nnitrous oxide 5%\nrefrigerant and other gases 3%\n\n\nDirect and indirect emissions\nfold-width of confidence interval-like interval: approx: 10-fold\naverage footprint of a UK person: 13 tonnes per year\nglobal average: 7 tonnes per year\nA large cheeseburger (3.2 kg CO2e) corresponds to approx. 6 hours of a 5 tonne year"
  },
  {
    "objectID": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#my-own-thoughts",
    "href": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#my-own-thoughts",
    "title": "How bad are bananas",
    "section": "My own thoughts",
    "text": "My own thoughts\n\nCarbon responsibility should work like this:\n\nThe total CO2e emitted in the entire world should be estimated\nThe responsibilities should be attributed (algorithmically)"
  },
  {
    "objectID": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#issues",
    "href": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#issues",
    "title": "How bad are bananas",
    "section": "Issues",
    "text": "Issues\n\nIs there a German translation?\nI should buy paper copies!\nMaybe initiate a school-project\nAsk for permission about the book: info@howbadarebananas.com\nIs there a good webpage belonging to the book?\nShiny app for “how much time of a 5 tonne year does this correspond to?”"
  },
  {
    "objectID": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#table",
    "href": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#table",
    "title": "How bad are bananas",
    "section": "Table",
    "text": "Table\nHere, I started to collect some of the data in the book and put them in a table:\n\n\n\n\n\n\n\n\n\nCO2e\nItem\n\n\n\n\n0.20\nPint of tap water\n\n\n0.03\nspam mail picked up by filter\n\n\n0.20\nshort e-mail from phone to phone\n\n\n0.30\nshort e-mail from laptop to laptop\n\n\n17.00\nlong email that takes 10 minutes to write and 3 minutes to read, sent from laptop to laptop\n\n\n26.00\nan email that takes you 10 minutes to write, sent to 100 people, 99 of whom take 3 seconds to realise they should ignore it and on the whom reads it\n\n\n0.50\none simple google search\n\n\n5.60\n5 minutes web browsing from a smartphone\n\n\n8.20\n5 minutes web browsing from a laptop\n\n\n0.80\nsingle text message\n\n\n3.00\nvery lightweight plastic carrier bag\n\n\n10.00\nheavier supermarket bag\n\n\n50.00\nheavweight ‘bag for life’\n\n\n2.00\nDyson Airblade\n\n\n10.00\none paper towel\n\n\n11.00\nstandard electric dryer\n\n\n12.00\nrecycled and lightweight paper carrier bag\n\n\n80.00\na fashion paper bag from mainly virgin paper\n\n\n8.00\nquick expert ironing of a shirt\n\n\n14.00\naverage ironing\n\n\n40.00\nironing of a thorougly crumped shirt\n\n\n2.00\none hour zoom call on 13-inch Mac-Book Pro\n\n\n10.00\none hour zoom call on an averagely efficient laptop\n\n\n50.00\none hour zoom call on desktop computer\n\n\n28.00\n100g portion of carrots – local, in season, full-size varieties\n\n\n83.00\n100g portion of carrots – local, in season, baby carrots\n\n\n90.00\n100g portion of carrots – full-size varieties, shipped within Europe"
  },
  {
    "objectID": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#plots",
    "href": "posts/2023-02-27-how-bad-are-bananas/2023-02-27-how-bad-are-bananas.html#plots",
    "title": "How bad are bananas",
    "section": "Plots",
    "text": "Plots"
  },
  {
    "objectID": "posts/2023-07-03-python-pandas/2023-07-03-python-pandas.html",
    "href": "posts/2023-07-03-python-pandas/2023-07-03-python-pandas.html",
    "title": "Python pandas",
    "section": "",
    "text": "pandas - Tutorials\nAccess R in Python chunk:\n\n\nr[\"mtcars\"]\n\n                      mpg  cyl   disp     hp  drat  ...   qsec   vs   am  gear  carb\nMazda RX4            21.0  6.0  160.0  110.0  3.90  ...  16.46  0.0  1.0   4.0   4.0\nMazda RX4 Wag        21.0  6.0  160.0  110.0  3.90  ...  17.02  0.0  1.0   4.0   4.0\nDatsun 710           22.8  4.0  108.0   93.0  3.85  ...  18.61  1.0  1.0   4.0   1.0\nHornet 4 Drive       21.4  6.0  258.0  110.0  3.08  ...  19.44  1.0  0.0   3.0   1.0\nHornet Sportabout    18.7  8.0  360.0  175.0  3.15  ...  17.02  0.0  0.0   3.0   2.0\nValiant              18.1  6.0  225.0  105.0  2.76  ...  20.22  1.0  0.0   3.0   1.0\nDuster 360           14.3  8.0  360.0  245.0  3.21  ...  15.84  0.0  0.0   3.0   4.0\nMerc 240D            24.4  4.0  146.7   62.0  3.69  ...  20.00  1.0  0.0   4.0   2.0\nMerc 230             22.8  4.0  140.8   95.0  3.92  ...  22.90  1.0  0.0   4.0   2.0\nMerc 280             19.2  6.0  167.6  123.0  3.92  ...  18.30  1.0  0.0   4.0   4.0\nMerc 280C            17.8  6.0  167.6  123.0  3.92  ...  18.90  1.0  0.0   4.0   4.0\nMerc 450SE           16.4  8.0  275.8  180.0  3.07  ...  17.40  0.0  0.0   3.0   3.0\nMerc 450SL           17.3  8.0  275.8  180.0  3.07  ...  17.60  0.0  0.0   3.0   3.0\nMerc 450SLC          15.2  8.0  275.8  180.0  3.07  ...  18.00  0.0  0.0   3.0   3.0\nCadillac Fleetwood   10.4  8.0  472.0  205.0  2.93  ...  17.98  0.0  0.0   3.0   4.0\nLincoln Continental  10.4  8.0  460.0  215.0  3.00  ...  17.82  0.0  0.0   3.0   4.0\nChrysler Imperial    14.7  8.0  440.0  230.0  3.23  ...  17.42  0.0  0.0   3.0   4.0\nFiat 128             32.4  4.0   78.7   66.0  4.08  ...  19.47  1.0  1.0   4.0   1.0\nHonda Civic          30.4  4.0   75.7   52.0  4.93  ...  18.52  1.0  1.0   4.0   2.0\nToyota Corolla       33.9  4.0   71.1   65.0  4.22  ...  19.90  1.0  1.0   4.0   1.0\nToyota Corona        21.5  4.0  120.1   97.0  3.70  ...  20.01  1.0  0.0   3.0   1.0\nDodge Challenger     15.5  8.0  318.0  150.0  2.76  ...  16.87  0.0  0.0   3.0   2.0\nAMC Javelin          15.2  8.0  304.0  150.0  3.15  ...  17.30  0.0  0.0   3.0   2.0\nCamaro Z28           13.3  8.0  350.0  245.0  3.73  ...  15.41  0.0  0.0   3.0   4.0\nPontiac Firebird     19.2  8.0  400.0  175.0  3.08  ...  17.05  0.0  0.0   3.0   2.0\nFiat X1-9            27.3  4.0   79.0   66.0  4.08  ...  18.90  1.0  1.0   4.0   1.0\nPorsche 914-2        26.0  4.0  120.3   91.0  4.43  ...  16.70  0.0  1.0   5.0   2.0\nLotus Europa         30.4  4.0   95.1  113.0  3.77  ...  16.90  1.0  1.0   5.0   2.0\nFord Pantera L       15.8  8.0  351.0  264.0  4.22  ...  14.50  0.0  1.0   5.0   4.0\nFerrari Dino         19.7  6.0  145.0  175.0  3.62  ...  15.50  0.0  1.0   5.0   6.0\nMaserati Bora        15.0  8.0  301.0  335.0  3.54  ...  14.60  0.0  1.0   5.0   8.0\nVolvo 142E           21.4  4.0  121.0  109.0  4.11  ...  18.60  1.0  1.0   4.0   2.0\n\n[32 rows x 11 columns]\n\n\n\nAccess Python object in R chunk\n\n\nxyz = 10\n\n\nlibrary(reticulate)\npy$xyz\n\n[1] 10\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\niris = pd.read_csv('iris.csv')\niris['Sepal.Length'].describe()\n\ncount    150.000000\nmean       5.843333\nstd        0.828066\nmin        4.300000\n25%        5.100000\n50%        5.800000\n75%        6.400000\nmax        7.900000\nName: Sepal.Length, dtype: float64\n\niris['Sepal.Width'].describe()\n\ncount    150.000000\nmean       3.057333\nstd        0.435866\nmin        2.000000\n25%        2.800000\n50%        3.000000\n75%        3.300000\nmax        4.400000\nName: Sepal.Width, dtype: float64\n\niris['total_length'] = iris['Sepal.Length'] + iris['Sepal.Width']\niris['total_length'].describe()\n\ncount    150.000000\nmean       8.900667\nstd        0.889272\nmin        6.800000\n25%        8.300000\n50%        8.850000\n75%        9.575000\nmax       11.700000\nName: total_length, dtype: float64\n\n# two identical results:\niris.loc[iris['total_length'] &gt; 10, 'total_length']\n\n15     10.1\n50     10.2\n102    10.1\n105    10.6\n107    10.2\n109    10.8\n117    11.5\n118    10.3\n120    10.1\n122    10.5\n125    10.4\n129    10.2\n130    10.2\n131    11.7\n135    10.7\nName: total_length, dtype: float64\n\niris[iris['total_length'] &gt; 10]['total_length']\n\n15     10.1\n50     10.2\n102    10.1\n105    10.6\n107    10.2\n109    10.8\n117    11.5\n118    10.3\n120    10.1\n122    10.5\n125    10.4\n129    10.2\n130    10.2\n131    11.7\n135    10.7\nName: total_length, dtype: float64\n\n\niris.loc[iris['total_length'] &gt; 10, 'total_length'] = 100"
  },
  {
    "objectID": "posts/2023-02_21-manual-colors-in-ggplot2/2023-02_21-manual-colors-in-ggplot2.html",
    "href": "posts/2023-02_21-manual-colors-in-ggplot2/2023-02_21-manual-colors-in-ggplot2.html",
    "title": "Manual colors in ggplot2",
    "section": "",
    "text": "After several instances of “relearning” how to use custom colour palettes in R, I have written this post in order to save some time when I want to use custom colours the next time.\n\nlibrary(ggplot2)\niris |&gt; ggplot(aes(Sepal.Length, Sepal.Width, colour = Species)) + \n  geom_point(size = 3) +\n  scale_colour_manual(values = c('lightgray', 'blue', 'black'), \n                      aesthetics = c('colour', 'fill'))"
  },
  {
    "objectID": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html",
    "href": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html",
    "title": "Chess ressources",
    "section": "",
    "text": "Link"
  },
  {
    "objectID": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#chess-related-packages-on-cran",
    "href": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#chess-related-packages-on-cran",
    "title": "Chess ressources",
    "section": "",
    "text": "Link"
  },
  {
    "objectID": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#nice-little-chess-engine",
    "href": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#nice-little-chess-engine",
    "title": "Chess ressources",
    "section": "nice little chess engine:",
    "text": "nice little chess engine:\nhttps://www.codertime.org/minimax-chess-engine-programming-r/"
  },
  {
    "objectID": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#interesting-people",
    "href": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#interesting-people",
    "title": "Chess ressources",
    "section": "Interesting people:",
    "text": "Interesting people:\n\nhttps://www.chessprogramming.org/Guy_Haworth\nhttps://www.chessprogramming.org/Kenneth_W._Regan"
  },
  {
    "objectID": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#interesting-publications",
    "href": "posts/2022-09-08-chess-ressources/2022-09-08-chess-ressources.html#interesting-publications",
    "title": "Chess ressources",
    "section": "interesting publications:",
    "text": "interesting publications:\n\nhttps://cse.buffalo.edu/~regan/papers/pdf/BHR2015ACG.pdf"
  },
  {
    "objectID": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html",
    "href": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html",
    "title": "Self-study: McElreath - Statistical Rethinking",
    "section": "",
    "text": "Website of the book\nStatistical rethinking lectures on youtube"
  },
  {
    "objectID": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html#general-stuff",
    "href": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html#general-stuff",
    "title": "Self-study: McElreath - Statistical Rethinking",
    "section": "",
    "text": "Website of the book\nStatistical rethinking lectures on youtube"
  },
  {
    "objectID": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html#lecture-1",
    "href": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html#lecture-1",
    "title": "Self-study: McElreath - Statistical Rethinking",
    "section": "Lecture 1",
    "text": "Lecture 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n       posterior_2  posterior_3\n [1,] 0.000000e+00 0.000000e+00\n [2,] 8.338945e-28 8.338945e-28\n [3,] 8.470870e-25 8.470870e-25\n [4,] 4.845672e-23 4.845672e-23\n [5,] 8.535940e-22 8.535940e-22\n [6,] 7.886021e-21 7.886021e-21\n [7,] 4.843656e-20 4.843656e-20\n [8,] 2.244608e-19 2.244608e-19\n [9,] 8.463615e-19 8.463615e-19\n[10,] 2.726299e-18 2.726299e-18\n[11,] 7.755988e-18 7.755988e-18\n[12,] 1.995488e-17 1.995488e-17\n[13,] 4.725159e-17 4.725159e-17\n[14,] 1.043556e-16 1.043556e-16\n[15,] 2.171886e-16 2.171886e-16\n[16,] 4.294773e-16 4.294773e-16\n[17,] 8.122594e-16 8.122594e-16\n[18,] 1.477229e-15 1.477229e-15\n[19,] 2.595039e-15 2.595039e-15\n[20,] 4.419889e-15 4.419889e-15\n[21,] 7.321976e-15 7.321976e-15\n[22,] 1.182961e-14 1.182961e-14\n[23,] 1.868315e-14 1.868315e-14\n[24,] 2.890305e-14 2.890305e-14\n[25,] 4.387490e-14 4.387490e-14\n[26,] 6.545435e-14 6.545435e-14\n[27,] 9.609549e-14 9.609549e-14\n[28,] 1.390063e-13 1.390063e-13\n[29,] 1.983357e-13 1.983357e-13\n[30,] 2.793963e-13 2.793963e-13\n[31,] 3.889283e-13 3.889283e-13\n[32,] 5.354101e-13 5.354101e-13\n[33,] 7.294212e-13 7.294212e-13\n[34,] 9.840637e-13 9.840637e-13\n[35,] 1.315450e-12 1.315450e-12\n[36,] 1.743265e-12 1.743265e-12\n[37,] 2.291406e-12 2.291406e-12\n[38,] 2.988716e-12 2.988716e-12\n[39,] 3.869812e-12 3.869812e-12\n[40,] 4.976027e-12 4.976027e-12\n[41,] 6.356464e-12 6.356464e-12\n[42,] 8.069180e-12 8.069180e-12\n[43,] 1.018252e-11 1.018252e-11\n[44,] 1.277658e-11 1.277658e-11\n[45,] 1.594485e-11 1.594485e-11\n[46,] 1.979607e-11 1.979607e-11\n[47,] 2.445616e-11 2.445616e-11\n[48,] 3.007052e-11 3.007052e-11\n[49,] 3.680640e-11 3.680640e-11\n[50,] 4.485558e-11 4.485558e-11"
  },
  {
    "objectID": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html#lecture-2---bayesian-inference",
    "href": "posts/2023-03-17-mcelreath-statistical-rethinking/2023-03-17-mcelreath-statistical-rethinking.html#lecture-2---bayesian-inference",
    "title": "Self-study: McElreath - Statistical Rethinking",
    "section": "Lecture 2 - Bayesian inference",
    "text": "Lecture 2 - Bayesian inference\n\nBayesian data analysis:\n\nFor each possible explanation of the data, count all the ways data can happen.\nExplanations with more ways to produce the data are more plausibel"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nThe iris dataset\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nEasier publishing\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nModel diagnostics for logistic regression\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nManaging python versions in RStudio\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nPython graphics\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nExploring the Python library statsmodels\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJul 4, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nPython pandas\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSpecifying mixed effects in lme4\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nInteresting R packages\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nPython study notes\n\n\n\n\n\n\n\nSelf-study\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nCoursera Deep Learning Specialization\n\n\n\n\n\n\n\nSelf-study\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSelf-study: Deep Learning by Goodfellow et al.\n\n\n\n\n\n\n\nSelf-study\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSelf-study: McElreath - Statistical Rethinking\n\n\n\n\n\n\n\nSelf-study\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nHow bad are bananas\n\n\n\n\n\n\n\nSustainibility\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nManual colors in ggplot2\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nStrange behavior in ggplot2\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSIRS model dynamics\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJan 19, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSustainibility data\n\n\n\n\n\n\n\nSustainibility\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nContribution plots\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJan 5, 2023\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nR interfaces to trial registries\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSimulate time to-event-data\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nKids per person and carbon footprint\n\n\n\n\n\n\n\nSustainibility\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nModel meadow\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nRetrieving and plotting COVID-19 data\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nLeo’s project\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSIR-like model with deSolve in deterministic and stochastic version\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nAntipsychotics\n\n\n\n\n\n\n\nPsychiatry\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nTimeline\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nPsychopharmaca and time\n\n\n\n\n\n\n\nPsychiatry\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nChess ressources\n\n\n\n\n\n\n\nMishmash\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nHumidity\n\n\n\n\n\n\n\nSustainibility\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\n  \n\n\n\n\nSIR model\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2022\n\n\nSebastian Gerdes\n\n\n\n\n\n\nNo matching items"
  }
]